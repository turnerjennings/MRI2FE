{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"MRI2FE","text":"<p>Patient-specific Finite Element Model Generation from medical imaging data</p>"},{"location":"#introduction","title":"Introduction","text":"<p>This package provides workflows for the generation of finite element (FE) models of the human head from patient-specific magnetic resonance imaging (MRI) and magnetic resonance elastography (MRE) data.  The objective of this toolkit is to provide fast and accurate generation of finite element head models (FEHMs) for a variety of physics and multi-physics analyses.  This package leverages industry standard tools including Advanced Normalization Tools (ANTs) for MRI transformation and segmentation <sup>1</sup><sup>2</sup>, and the Computational Geometry Algorithms Library (CGAL) for meshing <sup>3</sup><sup>4</sup>.</p>"},{"location":"#installation","title":"Installation","text":""},{"location":"#installing-from-wheel","title":"Installing from wheel","text":"<p>To install the package, download the appropriate wheel file from the most recent release, and then install on your local machine</p> <pre><code>\npip install ./name-of-wheel.whl\n\n</code></pre>"},{"location":"#installing-from-source","title":"Installing from source","text":"<p>To install the package from source, download or clone the repository to your local machine.  Run the appropriate installation script for your system, which will install all dependencies as well as the package.</p> <pre><code>git clone https://github.com/turnerjennings/MRI2FE\n\ncd MRI2FE\n\n#if on windows\n./install_windows.bat\n\n#if on mac\n./install_mac.sh\n\n#if on linux\n./install_linux.sh\n</code></pre> <p>On Windows, after installation from source you may run into an error stating \"DLL load failed\".  This issue occurs intermittently on Windows and is due to the dependencies for the CGAL library not linking correctly.  To address the issue, try reinstalling.  If the issue persists, find the location of the DLLs \"gmp-10.dll\" and \"mpfr6.dll\" in the ./vcpkg directory and copy them to the installation location.</p> <p>On Windows, there is an intermittent issue during installation where certain boost libraries cannot be located.  Re-running the installation consistently fixes this issue.</p> <ol> <li> <p>Nicholas J Tustison, Philip A Cook, Andrew J Holbrook, Hans J Johnson, John Muschelli, Gabriel A Devenyi, Jeffrey T Duda, Sandhitsu R Das, Nicholas C Cullen, Daniel L Gillen, and others. The antsx ecosystem for quantitative biological and medical imaging. Scientific reports, 11(1):9068, 2021.\u00a0\u21a9</p> </li> <li> <p>Arno Klein, Jesper Andersson, Babak A. Ardekani, John Ashburner, Brian Avants, Ming-Chang Chiang, Gary E. Christensen, D. Louis Collins, James Gee, Pierre Hellier, Joo Hyun Song, Mark Jenkinson, Claude Lepage, Daniel Rueckert, Paul Thompson, Tom Vercauteren, Roger P. Woods, J. John Mann, and Ramin V. Parsey. Evaluation of 14 nonlinear deformation algorithms applied to human brain mri registration. NeuroImage, 46(3):786\u2013802, 2009. URL: https://www.sciencedirect.com/science/article/pii/S1053811908012974, doi:https://doi.org/10.1016/j.neuroimage.2008.12.037.\u00a0\u21a9</p> </li> <li> <p>The CGAL Project. CGAL User and Reference Manual. CGAL Editorial Board, 6.0.1 edition, 2024. URL: https://doc.cgal.org/6.0.1/Manual/packages.html.\u00a0\u21a9</p> </li> <li> <p>Pierre Alliez, Cl\u00e9ment Jamin, Laurent Rineau, St\u00e9phane Tayeb, Jane Tournois, and Mariette Yvinec. 3D mesh generation. In CGAL User and Reference Manual. CGAL Editorial Board, 6.0.1 edition, 2024. URL: https://doc.cgal.org/6.0.1/Manual/packages.html#PkgMesh3.\u00a0\u21a9</p> </li> </ol>"},{"location":"api/","title":"API Reference","text":"<p>The following sections summarize all individual functions and classes contained in the library.</p>"},{"location":"api/#model-builder-pipeline","title":"Model builder pipeline","text":""},{"location":"api/#MRI2FE.Pipelines.FEModelbuilder","title":"<code>MRI2FE.Pipelines.FEModelbuilder</code>","text":"Source code in <code>src/MRI2FE/Pipelines/new_model.py</code> <pre><code>class FEModelbuilder:\n    def __init__(\n        self, title: str = \"\", source: str = \"\", imgout: Optional[str] = None\n    ):\n        \"\"\"Initialize the FEModel object to store model data.\n\n        Args:\n            title (str, optional): Optional title for the model which will be written to output solver decks. Defaults to \"\".\n            source (str, optional): Optional source folder for model for internal tracking. Defaults to \"\".\n        \"\"\"\n        self.model = FEModel(title=title, source=source, imgout=imgout)\n\n    def mesh(\n        self,\n        img_path: str,\n        img_labels: Optional[List[str]] = None,\n        optimize: bool = False,\n        **kwargs,\n    ):\n        \"\"\"Generate a tetrahedral mesh from labeled MRI data and store in the FEModel object\n\n        Args:\n            img_path (str): Path to segmented, labeled MRI image.\n            img_labels (List[str], optional): Optional labels providing names for each region of the labeled image. Defaults to None.\n            optimize (bool, optional): Whether to perform post-process optimization on the tetrahedral mesh.  Increases quality and run time. Defaults to False.\n        \"\"\"\n        self.labeled_geom = image_read(img_path)\n        self.geom_labels = img_labels\n\n        msh = mesh_from_nifti(filepath=img_path, optimize=optimize, **kwargs)\n\n        self.model.from_meshio(msh, region_names=img_labels)\n\n        return self\n\n    def map_mre(\n        self,\n        target_label: int = 4,\n        MRE_type: Literal[\n            \"stiffness_damping\", \"complex_shear\"\n        ] = \"stiffness_damping\",\n        MRE_geom: Optional[List[Union[str, Any]]] = None,\n        MRE_mask: Optional[Union[str, Any]] = None,\n        MRE_frequency: Optional[List[float]] = None,\n        MRE_to_transform: Optional[List[Tuple[Union[str, Any]]]] = None,\n        n_segs: int = 5,\n        **kwargs,\n    ):\n        \"\"\"Calculate material model coefficients and map MRE material assignments onto an ROI on the mesh.\n\n        Args:\n            target_label (int, optional): Target integer label on the labeled image to map MRE material properties to. Defaults to 4.\n            MRE_type (\"stiffness_damping\" or \"complex_shear\", optional): Specify whether MRE files are provided as shear stiffness and damping ratio or as storage and loss moduli. Defaults to \"stiffness_damping\".\n            MRE_geom (List[str  |  Any], optional): List of images or paths to images for MRE geometries at each frequency. Defaults to None.\n            MRE_mask (str | Any, optional): ROI mask for MRE geometry. Defaults to None.\n            MRE_frequency (List[float], optional): List of frequencies for each MRE geometry image. Defaults to None.\n            MRE_to_transform (List[Tuple[str  |  Any]], optional): List of tuples of strings or MRE images.  Each tuple represents either shear/damping or storage/loss moduli at a frequency given in MRE_frequency. Defaults to None.\n            n_segs (int, optional): Number of segments to discretize the MRE material properties into. Defaults to 5.\n\n        \"\"\"\n        _, transformed = coregister_MRE_images(\n            segmented_geom=self.labeled_geom,\n            target_label=target_label,\n            MRE_geom=MRE_geom,\n            MRE_mask=MRE_mask,\n            MRE_to_transform=MRE_to_transform,\n            imgout=cast(str, self.model.metadata[\"imgout\"]),\n            **kwargs,\n        )\n        # handle edge case if only one MRE frequency is used\n        if isinstance(transformed, tuple):\n            transformed = [transformed]\n\n        self.transformed_mre = transformed\n\n        labels, region_avgs = segment_MRE_regions(\n            img_list=transformed,\n            n_segs=n_segs,\n            imgout=cast(str, self.model.metadata[\"imgout\"]),\n            imgout_geom=self.labeled_geom,\n        )\n\n        regions_props = []\n        for i in range(len(region_avgs)):\n            if MRE_type == \"stiffness_damping\":\n                regions_props.append(\n                    calculate_prony(\n                        mu=region_avgs[\"1\"][i],\n                        xi=region_avgs[\"2\"][i],\n                        w=MRE_frequency,\n                    )\n                )\n\n            elif MRE_type == \"complex_shear\":\n                regions_props.append(\n                    calculate_prony(\n                        gp=region_avgs[\"1\"][i],\n                        gpp=region_avgs[\"2\"][i],\n                        w=MRE_frequency,\n                    )\n                )\n\n        if self.geom_labels is not None:\n            self.model = map_MRE_to_mesh(\n                self.model,\n                label_img=labels,\n                region_properties=regions_props,\n                target_region_id=target_label,\n                region_prefix=self.geom_labels[target_label - 1],\n            )\n        else:\n            self.model = map_MRE_to_mesh(\n                self.model,\n                label_img=labels,\n                region_properties=regions_props,\n                target_region_id=target_label,\n            )\n\n        return self\n\n    def write(self, fpath: str, type: Literal[\"lsdyna\"] = \"lsdyna\"):\n        \"\"\"Write model to output solver deck\n\n        Args:\n            fpath (str): File path to save output to.\n            type (\"lsdyna\", optional): Output type to be saved.  Currently, only LS-DYNA is supported. Defaults to \"lsdyna\".\n\n        \"\"\"\n        if type == \"lsdyna\":\n            self.model.write_lsdyna(fpath)\n\n        return self\n\n    def build(self):\n        \"\"\"Return generated FEModel\"\"\"\n        return self.model\n</code></pre>"},{"location":"api/#MRI2FE.Pipelines.FEModelbuilder.__init__","title":"<code>__init__(title='', source='', imgout=None)</code>","text":"<p>Initialize the FEModel object to store model data.</p> <p>Parameters:</p> Name Type Description Default <code>title</code> <code>str</code> <p>Optional title for the model which will be written to output solver decks. Defaults to \"\".</p> <code>''</code> <code>source</code> <code>str</code> <p>Optional source folder for model for internal tracking. Defaults to \"\".</p> <code>''</code> Source code in <code>src/MRI2FE/Pipelines/new_model.py</code> <pre><code>def __init__(\n    self, title: str = \"\", source: str = \"\", imgout: Optional[str] = None\n):\n    \"\"\"Initialize the FEModel object to store model data.\n\n    Args:\n        title (str, optional): Optional title for the model which will be written to output solver decks. Defaults to \"\".\n        source (str, optional): Optional source folder for model for internal tracking. Defaults to \"\".\n    \"\"\"\n    self.model = FEModel(title=title, source=source, imgout=imgout)\n</code></pre>"},{"location":"api/#MRI2FE.Pipelines.FEModelbuilder.build","title":"<code>build()</code>","text":"<p>Return generated FEModel</p> Source code in <code>src/MRI2FE/Pipelines/new_model.py</code> <pre><code>def build(self):\n    \"\"\"Return generated FEModel\"\"\"\n    return self.model\n</code></pre>"},{"location":"api/#MRI2FE.Pipelines.FEModelbuilder.map_mre","title":"<code>map_mre(target_label=4, MRE_type='stiffness_damping', MRE_geom=None, MRE_mask=None, MRE_frequency=None, MRE_to_transform=None, n_segs=5, **kwargs)</code>","text":"<p>Calculate material model coefficients and map MRE material assignments onto an ROI on the mesh.</p> <p>Parameters:</p> Name Type Description Default <code>target_label</code> <code>int</code> <p>Target integer label on the labeled image to map MRE material properties to. Defaults to 4.</p> <code>4</code> <code>MRE_type</code> <code>stiffness_damping or complex_shear</code> <p>Specify whether MRE files are provided as shear stiffness and damping ratio or as storage and loss moduli. Defaults to \"stiffness_damping\".</p> <code>'stiffness_damping'</code> <code>MRE_geom</code> <code>List[str | Any]</code> <p>List of images or paths to images for MRE geometries at each frequency. Defaults to None.</p> <code>None</code> <code>MRE_mask</code> <code>str | Any</code> <p>ROI mask for MRE geometry. Defaults to None.</p> <code>None</code> <code>MRE_frequency</code> <code>List[float]</code> <p>List of frequencies for each MRE geometry image. Defaults to None.</p> <code>None</code> <code>MRE_to_transform</code> <code>List[Tuple[str | Any]]</code> <p>List of tuples of strings or MRE images.  Each tuple represents either shear/damping or storage/loss moduli at a frequency given in MRE_frequency. Defaults to None.</p> <code>None</code> <code>n_segs</code> <code>int</code> <p>Number of segments to discretize the MRE material properties into. Defaults to 5.</p> <code>5</code> Source code in <code>src/MRI2FE/Pipelines/new_model.py</code> <pre><code>def map_mre(\n    self,\n    target_label: int = 4,\n    MRE_type: Literal[\n        \"stiffness_damping\", \"complex_shear\"\n    ] = \"stiffness_damping\",\n    MRE_geom: Optional[List[Union[str, Any]]] = None,\n    MRE_mask: Optional[Union[str, Any]] = None,\n    MRE_frequency: Optional[List[float]] = None,\n    MRE_to_transform: Optional[List[Tuple[Union[str, Any]]]] = None,\n    n_segs: int = 5,\n    **kwargs,\n):\n    \"\"\"Calculate material model coefficients and map MRE material assignments onto an ROI on the mesh.\n\n    Args:\n        target_label (int, optional): Target integer label on the labeled image to map MRE material properties to. Defaults to 4.\n        MRE_type (\"stiffness_damping\" or \"complex_shear\", optional): Specify whether MRE files are provided as shear stiffness and damping ratio or as storage and loss moduli. Defaults to \"stiffness_damping\".\n        MRE_geom (List[str  |  Any], optional): List of images or paths to images for MRE geometries at each frequency. Defaults to None.\n        MRE_mask (str | Any, optional): ROI mask for MRE geometry. Defaults to None.\n        MRE_frequency (List[float], optional): List of frequencies for each MRE geometry image. Defaults to None.\n        MRE_to_transform (List[Tuple[str  |  Any]], optional): List of tuples of strings or MRE images.  Each tuple represents either shear/damping or storage/loss moduli at a frequency given in MRE_frequency. Defaults to None.\n        n_segs (int, optional): Number of segments to discretize the MRE material properties into. Defaults to 5.\n\n    \"\"\"\n    _, transformed = coregister_MRE_images(\n        segmented_geom=self.labeled_geom,\n        target_label=target_label,\n        MRE_geom=MRE_geom,\n        MRE_mask=MRE_mask,\n        MRE_to_transform=MRE_to_transform,\n        imgout=cast(str, self.model.metadata[\"imgout\"]),\n        **kwargs,\n    )\n    # handle edge case if only one MRE frequency is used\n    if isinstance(transformed, tuple):\n        transformed = [transformed]\n\n    self.transformed_mre = transformed\n\n    labels, region_avgs = segment_MRE_regions(\n        img_list=transformed,\n        n_segs=n_segs,\n        imgout=cast(str, self.model.metadata[\"imgout\"]),\n        imgout_geom=self.labeled_geom,\n    )\n\n    regions_props = []\n    for i in range(len(region_avgs)):\n        if MRE_type == \"stiffness_damping\":\n            regions_props.append(\n                calculate_prony(\n                    mu=region_avgs[\"1\"][i],\n                    xi=region_avgs[\"2\"][i],\n                    w=MRE_frequency,\n                )\n            )\n\n        elif MRE_type == \"complex_shear\":\n            regions_props.append(\n                calculate_prony(\n                    gp=region_avgs[\"1\"][i],\n                    gpp=region_avgs[\"2\"][i],\n                    w=MRE_frequency,\n                )\n            )\n\n    if self.geom_labels is not None:\n        self.model = map_MRE_to_mesh(\n            self.model,\n            label_img=labels,\n            region_properties=regions_props,\n            target_region_id=target_label,\n            region_prefix=self.geom_labels[target_label - 1],\n        )\n    else:\n        self.model = map_MRE_to_mesh(\n            self.model,\n            label_img=labels,\n            region_properties=regions_props,\n            target_region_id=target_label,\n        )\n\n    return self\n</code></pre>"},{"location":"api/#MRI2FE.Pipelines.FEModelbuilder.mesh","title":"<code>mesh(img_path, img_labels=None, optimize=False, **kwargs)</code>","text":"<p>Generate a tetrahedral mesh from labeled MRI data and store in the FEModel object</p> <p>Parameters:</p> Name Type Description Default <code>img_path</code> <code>str</code> <p>Path to segmented, labeled MRI image.</p> required <code>img_labels</code> <code>List[str]</code> <p>Optional labels providing names for each region of the labeled image. Defaults to None.</p> <code>None</code> <code>optimize</code> <code>bool</code> <p>Whether to perform post-process optimization on the tetrahedral mesh.  Increases quality and run time. Defaults to False.</p> <code>False</code> Source code in <code>src/MRI2FE/Pipelines/new_model.py</code> <pre><code>def mesh(\n    self,\n    img_path: str,\n    img_labels: Optional[List[str]] = None,\n    optimize: bool = False,\n    **kwargs,\n):\n    \"\"\"Generate a tetrahedral mesh from labeled MRI data and store in the FEModel object\n\n    Args:\n        img_path (str): Path to segmented, labeled MRI image.\n        img_labels (List[str], optional): Optional labels providing names for each region of the labeled image. Defaults to None.\n        optimize (bool, optional): Whether to perform post-process optimization on the tetrahedral mesh.  Increases quality and run time. Defaults to False.\n    \"\"\"\n    self.labeled_geom = image_read(img_path)\n    self.geom_labels = img_labels\n\n    msh = mesh_from_nifti(filepath=img_path, optimize=optimize, **kwargs)\n\n    self.model.from_meshio(msh, region_names=img_labels)\n\n    return self\n</code></pre>"},{"location":"api/#MRI2FE.Pipelines.FEModelbuilder.write","title":"<code>write(fpath, type='lsdyna')</code>","text":"<p>Write model to output solver deck</p> <p>Parameters:</p> Name Type Description Default <code>fpath</code> <code>str</code> <p>File path to save output to.</p> required <code>type</code> <code>lsdyna</code> <p>Output type to be saved.  Currently, only LS-DYNA is supported. Defaults to \"lsdyna\".</p> <code>'lsdyna'</code> Source code in <code>src/MRI2FE/Pipelines/new_model.py</code> <pre><code>def write(self, fpath: str, type: Literal[\"lsdyna\"] = \"lsdyna\"):\n    \"\"\"Write model to output solver deck\n\n    Args:\n        fpath (str): File path to save output to.\n        type (\"lsdyna\", optional): Output type to be saved.  Currently, only LS-DYNA is supported. Defaults to \"lsdyna\".\n\n    \"\"\"\n    if type == \"lsdyna\":\n        self.model.write_lsdyna(fpath)\n\n    return self\n</code></pre>"},{"location":"api/#meshing","title":"Meshing","text":""},{"location":"api/#MRI2FE.mesh_from_nifti","title":"<code>MRI2FE.mesh_from_nifti(filepath, optimize=False, facetAngle=30.0, facetSize=1.0, facetDistance=4.0, cellRadiusEdgeRatio=3.0, cellSize=1.0)</code>","text":"Source code in <code>src/MRI2FE/generate_mesh.py</code> <pre><code>def mesh_from_nifti(\n    filepath: str,\n    optimize: bool = False,\n    facetAngle: float = 30.0,\n    facetSize: float = 1.0,\n    facetDistance: float = 4.0,\n    cellRadiusEdgeRatio: float = 3.0,\n    cellSize: float = 1.0,\n) -&gt; meshio.Mesh:\n    if not os.path.exists(filepath):\n        raise ValueError(f\"input filepath {filepath} does not exist\")\n\n    image = image_read(filepath)\n\n    origin = image.origin\n\n    transfer_path = nifti_to_inr(image=image)\n\n    mesh_path = mesh_wrapper(\n        transfer_path,\n        optimize,\n        facetAngle,\n        facetSize,\n        facetDistance,\n        cellRadiusEdgeRatio,\n        cellSize,\n    )\n\n    if not os.path.exists(mesh_path):\n        raise ValueError(f\"Mesh wrapper did not create mesh at {mesh_path}\")\n\n    try:\n        mesh: meshio.Mesh = meshio.read(mesh_path)\n\n        mesh.points = mesh.points + np.array(origin)\n\n        return mesh\n    except ValueError:\n        raise ValueError(\n            \"Error loading mesh from file, mesh may be too large...\"\n        )\n</code></pre>"},{"location":"api/#mre-coregistration","title":"MRE Coregistration","text":""},{"location":"api/#MRI2FE.MRE.coregister_MRE_images","title":"<code>MRI2FE.MRE.coregister_MRE_images(segmented_geom, target_label=4, segmented_mask=None, MRE_geom=None, MRE_mask=None, MRE_to_transform=None, imgout=None, type_of_transform='Affine')</code>","text":"<p>Coregister MRE geometry image to segmented geometry image, and transform corresponding MRE images.</p> <p>Parameters:</p> Name Type Description Default <code>segmented_geom</code> <code>Union[str, ANTsImage]</code> <p>Segmented geometry image used for mesh creation</p> required <code>target_label</code> <code>int</code> <p>Label for ROI on geometry image. Used to create geometry mask if one is not provided. Defaults to 4.</p> <code>4</code> <code>segmented_mask</code> <code>Union[str, ANTsImage]</code> <p>Binary mask for ROI on geometry image. Defaults to None.</p> <code>None</code> <code>MRE_geom</code> <code>List[Union[str, ANTsImage]]</code> <p>List of geometry images associated with MRE at different frequencies. Defaults to None.</p> <code>None</code> <code>MRE_mask</code> <code>Union[str, ANTsImage]</code> <p>Binary mask associated with ROI in MRE images. Defaults to None.</p> <code>None</code> <code>MRE_to_transform</code> <code>List[Tuple[Union[str, ANTsImage]]]</code> <p>List of tuples, each tuple containing MRE images associated with one of the MRE_geom images provided. Defaults to None.</p> <code>None</code> <code>imgout</code> <code>str</code> <p>Filepath to save validation images of the transformations applied. Defaults to None.</p> <code>None</code> <code>type_of_transform</code> <code>str</code> <p>Type of transform, see Antspy registration documentation for guidance. Defaults to \"Affine\".</p> <code>'Affine'</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>No MRE/segmented geometry image provided</p> <code>FileNotFoundError</code> <p>MRE/segmented geometry files not found</p> <code>TypeError</code> <p>Image files are not a filepath string or AntsImage</p> <code>ValueError</code> <p>Transform could not be resolved</p> <code>ValueError</code> <p>MRE_geom and MRE_to_Transform are different lengths</p> <code>ValueError</code> <p>imgout path could not be found</p> <p>Returns:</p> Name Type Description <code>Transformations</code> <code>List</code> <p>list of transformations</p> <code>Transformed_images</code> <code>List</code> <p>list of transformed image tuples</p> Source code in <code>src/MRI2FE/MRE/MRE_coregistration.py</code> <pre><code>def coregister_MRE_images(\n    segmented_geom: Union[str, ANTsImage],\n    target_label: int = 4,\n    segmented_mask: Optional[Union[str, ANTsImage]] = None,\n    MRE_geom: Optional[List[Union[str, ANTsImage]]] = None,\n    MRE_mask: Optional[Union[str, ANTsImage]] = None,\n    MRE_to_transform: Optional[List[Tuple[Union[str, ANTsImage]]]] = None,\n    imgout: Optional[str] = None,\n    type_of_transform: str = \"Affine\",\n):\n    \"\"\"Coregister MRE geometry image to segmented geometry image, and transform corresponding MRE images.\n\n    Args:\n        segmented_geom (Union[str, ANTsImage]): Segmented geometry image used for mesh creation\n        target_label (int, optional): Label for ROI on geometry image. Used to create geometry mask if one is not provided. Defaults to 4.\n        segmented_mask (Union[str,ANTsImage], optional): Binary mask for ROI on geometry image. Defaults to None.\n        MRE_geom (List[Union[str, ANTsImage]], optional): List of geometry images associated with MRE at different frequencies. Defaults to None.\n        MRE_mask (Union[str, ANTsImage], optional): Binary mask associated with ROI in MRE images. Defaults to None.\n        MRE_to_transform (List[Tuple[Union[str, ANTsImage]]], optional): List of tuples, each tuple containing MRE images associated with one of the MRE_geom images provided. Defaults to None.\n        imgout (str, optional): Filepath to save validation images of the transformations applied. Defaults to None.\n        type_of_transform (str, optional): Type of transform, see Antspy registration documentation for guidance. Defaults to \"Affine\".\n\n    Raises:\n        ValueError: No MRE/segmented geometry image provided\n        FileNotFoundError: MRE/segmented geometry files not found\n        TypeError: Image files are not a filepath string or AntsImage\n        ValueError: Transform could not be resolved\n        ValueError: MRE_geom and MRE_to_Transform are different lengths\n        ValueError: imgout path could not be found\n\n    Returns:\n        Transformations (List): list of transformations\n        Transformed_images (List): list of transformed image tuples\n    \"\"\"\n    if segmented_geom is None:\n        raise ValueError(\"Segmented geometry image is required\")\n\n    if MRE_geom is None:\n        raise ValueError(\"MRE geometry image is required\")\n\n    MRE_geom = _entry_to_list(MRE_geom)\n    MRE_to_transform = _entry_to_list(MRE_to_transform)\n\n    # Load segmented geometry\n    if isinstance(segmented_geom, str):\n        if not os.path.exists(segmented_geom):\n            raise FileNotFoundError(\n                f\"Geometry mask file not found: {segmented_geom}\"\n            )\n        segmented_geom = image_read(segmented_geom)\n    elif not isinstance(segmented_geom, ANTsImage):\n        raise TypeError(\n            \"geom_mask must be either a filepath string or ANTsImage object\"\n        )\n\n    # Load segmented mask or threshold image\n    if segmented_mask is None:\n        segmented_mask = threshold_image(\n            segmented_geom,\n            low_thresh=target_label - 0.01,\n            high_thresh=target_label + 1.01,\n        )\n    elif isinstance(segmented_mask, str):\n        if not os.path.exists(segmented_mask):\n            raise FileNotFoundError(\n                f\"Geometry image file not found: {segmented_mask}\"\n            )\n        segmented_geom = image_read(segmented_geom)\n    elif not isinstance(segmented_geom, ANTsImage):\n        raise TypeError(\"geom must be a filepath string\")\n\n    # load MRE geometries\n    MRE_geom_imgs = []\n    for img in MRE_geom:\n        MRE_geom_imgs.append(_ensure_image(img))\n\n    # load MRE mask\n    if MRE_mask is not None and isinstance(MRE_mask, str):\n        if not os.path.exists(MRE_mask):\n            raise FileNotFoundError(\n                f\"Geometry image file not found: {MRE_mask}\"\n            )\n        MRE_mask = image_read(MRE_mask)\n    elif not isinstance(segmented_geom, ANTsImage):\n        raise TypeError(\n            \"geom must be either a filepath string or ANTsImage object\"\n        )\n\n    # load images to transform\n    MRE_transform_imgs = []\n    for imgs in MRE_to_transform:\n        MRE_transform_imgs.append(_ensure_tuple(imgs))\n\n    if len(MRE_transform_imgs) != len(MRE_geom_imgs):\n        raise ValueError(\n            f\"{len(MRE_geom_imgs)} geometry images were provided but {len(MRE_transform_imgs)} transform tuples were provided\"\n        )\n\n    # create each transform and image\n    transformations = []\n    transformed_images = []\n    for idx, (geom, img_tuple) in enumerate(\n        zip(MRE_geom_imgs, MRE_transform_imgs)\n    ):\n        # resample geometry to MRE image\n        geom_resample = resample_image(\n            segmented_geom, geom.shape, use_voxels=True\n        )\n        mask_resample = resample_image(\n            segmented_mask, geom.shape, use_voxels=True\n        )\n\n        # calculate transform\n        try:\n            if MRE_mask is not None:\n                tx = registration(\n                    fixed=geom_resample,\n                    moving=geom,\n                    type_of_transform=type_of_transform,\n                    mask=mask_resample,\n                    moving_mask=MRE_mask,\n                )\n            else:\n                tx = registration(\n                    fixed=geom_resample,\n                    moving=geom,\n                    type_of_transform=type_of_transform,\n                    mask=mask_resample,\n                )\n        except ValueError:\n            print(f\"transformation failed on image {idx}\")\n\n        transformations.append(tx[\"fwdtransforms\"])\n\n        # apply transforms\n        transformed_tuple = tuple(\n            apply_transforms(\n                fixed=geom_resample,\n                moving=img,\n                transformlist=tx[\"fwdtransforms\"],\n            )\n            for img in img_tuple\n        )\n        transformed_images.append(transformed_tuple)\n        print(f\"in MRE coregistration: {imgout}\")\n        if imgout is not None:\n            if not os.path.exists(imgout):\n                raise ValueError(\"imgout directory does not exist\")\n            else:\n                base = os.path.join(imgout, f\"MRE{idx}_coreg.png\")\n                plot(\n                    segmented_geom,\n                    overlay=tx[\"warpedmovout\"],\n                    overlay_cmap=\"Dark2\",\n                    overlay_alpha=0.8,\n                    filename=base,\n                    axis=0,\n                )\n\n    # return single dict or list of dicts\n    if len(transformed_images) == 0:\n        raise ValueError(\"No results generated from MRE coregistration\")\n    elif len(transformed_images) == 1:\n        return transformations[0], transformed_images[0]\n    else:\n        return transformations, transformed_images\n</code></pre>"},{"location":"api/#MRI2FE.MRE.segment_MRE_regions","title":"<code>MRI2FE.MRE.segment_MRE_regions(img_list, n_segs=5, imgout=None, imgout_geom=None)</code>","text":"<p>Kmeans segmentation of MRE images</p> <p>Parameters:</p> Name Type Description Default <code>img_list</code> <code>List[Tuple[ANTsImage]]</code> <p>List of tuples of ANTsImage, each tuple representing the two images available for MRE at a given frequency.</p> required <code>n_segs</code> <code>int</code> <p>Number of segments to generate. Defaults to 5.</p> <code>5</code> <code>imgout</code> <code>str</code> <p>optional directory path to save validation images.  Defaults ot None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Labels</code> <code>ANTsImage</code> <p>Image containing integer labels for each region of the MRE images.</p> <code>km_ants</code> <code>dict</code> <p>Dictionary containing average properties for each region.  Keys are \"1\" and \"2\" for the two input images for each tuple, each key contains a list of length n_tuples which has the average properties for that cluster</p> Source code in <code>src/MRI2FE/MRE/MRE_coregistration.py</code> <pre><code>def segment_MRE_regions(\n    img_list: List[Tuple[ANTsImage, ANTsImage]],\n    n_segs: int = 5,\n    imgout: Optional[str] = None,\n    imgout_geom: Union[str, ANTsImage] = None,\n):\n    \"\"\"Kmeans segmentation of MRE images\n\n    Args:\n        img_list (List[Tuple[ANTsImage]]): List of tuples of ANTsImage, each tuple representing the two images available for MRE at a given frequency.\n        n_segs (int, optional): Number of segments to generate. Defaults to 5.\n        imgout (str, optional): optional directory path to save validation images.  Defaults ot None.\n\n    Returns:\n        Labels (ANTsImage): Image containing integer labels for each region of the MRE images.\n        km_ants (dict): Dictionary containing average properties for each region.  Keys are \"1\" and \"2\" for the two input images for each tuple, each key contains a list of length n_tuples which has the average properties for that cluster\n    \"\"\"\n\n    # check image list contents:\n    for tup in img_list:\n        for entry in tup:\n            if not isinstance(entry, ANTsImage):\n                raise ValueError(\n                    \"All entries in img_list must be tuples of AntsImage\"\n                )\n\n    # calculate array dimensions\n    ants_size = img_list[0][0].numpy().size\n    ants_shape = img_list[0][0].numpy().shape\n    n_img = 2\n    n_features = len(img_list)\n\n    # build kmeans array\n    samples_list = []\n    for tup in img_list:\n        samples_list.append(tup[0].numpy().flatten())\n        samples_list.append(tup[1].numpy().flatten())\n\n    samples = np.array(\n        samples_list\n    ).T  # rows = samples (voxels), columns = features (MRE values)\n\n    if not samples.shape == (ants_size, n_features * n_img):\n        raise ValueError(\n            \"internal error: sample dimensions do not match post k-means array assembly\"\n        )\n\n    kmeans = KMeans(n_clusters=n_segs + 1).fit(samples)\n    # create label image\n    km_label_array = kmeans.labels_.reshape(ants_shape)\n\n    km_label_ants = new_image_like(img_list[0][0], km_label_array)\n\n    # create region average properties\n    print(kmeans.cluster_centers_.shape)\n    km_avgs: dict = {\"1\": [], \"2\": []}\n    for row in kmeans.cluster_centers_:\n        label_1 = row[::2].tolist()\n        label_2 = row[1::2].tolist()\n\n        km_avgs[\"1\"].append(label_1)\n        km_avgs[\"2\"].append(label_2)\n\n    if imgout is not None:\n        if not os.path.exists(imgout):\n            raise ValueError(\"imgout directory does not exist\")\n        elif imgout_geom is None:\n            for idx, img in enumerate(img_list):\n                base = os.path.join(imgout, f\"MRE{idx}_segmentation.png\")\n                plot(\n                    img[0],\n                    overlay=km_label_ants,\n                    overlay_cmap=\"tab10\",\n                    overlay_alpha=0.5,\n                    filename=base,\n                    axis=0,\n                )\n        elif isinstance(imgout_geom, str):\n            img = image_read(imgout_geom)\n            base = os.path.join(imgout, \"MRE_segmentation.png\")\n            plot(\n                img,\n                overlay=km_label_ants,\n                overlay_cmap=\"tab10\",\n                overlay_alpha=0.5,\n                filename=base,\n                axis=0,\n            )\n        elif isinstance(imgout_geom, ANTsImage):\n            base = os.path.join(imgout, \"MRE_segmentation.png\")\n            plot(\n                imgout_geom,\n                overlay=km_label_ants,\n                overlay_cmap=\"tab10\",\n                overlay_alpha=0.5,\n                filename=base,\n                axis=0,\n            )\n        else:\n            raise ValueError(\"imgout_geom must be a string or ANTsImage\")\n\n    return km_label_ants, km_avgs\n</code></pre>"},{"location":"api/#MRI2FE.MRE.calculate_prony","title":"<code>MRI2FE.MRE.calculate_prony</code>","text":""},{"location":"api/#MRI2FE.MRE.calculate_prony.calculate_prony","title":"<code>calculate_prony(gp=None, gpp=None, mu=None, xi=None, w=None, tol=0.001)</code>","text":"<p>Calculate the 1st order prony series equivalent to the complex shear modulus representation of brain tissue viscoelasticity</p> <p>Parameters:</p> Name Type Description Default <code>gp</code> <code>array - like</code> <p>storage moduli at different frequencies. If gp is provided, gpp must also be provided.</p> <code>None</code> <code>gpp</code> <code>array - like</code> <p>loss moduli at different frequencies.  If gpp is provided, gp must also be provided.</p> <code>None</code> <code>mu</code> <code>array - like</code> <p>Shear stiffness at different frequencies.  If mu is provided, xi must also be provided.</p> <code>None</code> <code>xi</code> <code>array - like</code> <p>Damping ratio at different frequencies.  If xi, is provided, mu must also be provided.</p> <code>None</code> <code>w</code> <code>array - like</code> <p>MRE frequency for each gp/gpp or mu/xi value, must follow the same order.</p> <code>None</code> <code>tol</code> <code>float</code> <p>Back calculation tolerance check. Defaults to 1.00e-3.</p> <code>0.001</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>gp/gpp or mu/xi not provided</p> <code>ValueError</code> <p>number of inputs on each array do not match</p> <code>ValueError</code> <p>Mu or Xi back-calculation out of range</p> <p>Returns:</p> Name Type Description <code>Ginf</code> <code>float</code> <p>long-time shear modulus</p> <code>G1</code> <code>float</code> <p>short-time shear modulus</p> <code>tau</code> <code>float</code> <p>short-time time constant</p> <code>gp</code> <code>float</code> <p>Storage modulus</p> <code>gpp</code> <code>float</code> <p>Loss modulus</p> Source code in <code>src/MRI2FE/MRE/calculate_prony.py</code> <pre><code>def calculate_prony(\n    gp: Optional[ArrayLike] = None,\n    gpp: Optional[ArrayLike] = None,\n    mu: Optional[ArrayLike] = None,\n    xi: Optional[ArrayLike] = None,\n    w: Optional[ArrayLike] = None,\n    tol=1.00e-3,\n):\n    \"\"\"Calculate the 1st order prony series equivalent to the complex shear modulus representation of brain tissue viscoelasticity\n\n    Args:\n        gp (array-like): storage moduli at different frequencies. If gp is provided, gpp must also be provided.\n        gpp (array-like): loss moduli at different frequencies.  If gpp is provided, gp must also be provided.\n        mu (array-like): Shear stiffness at different frequencies.  If mu is provided, xi must also be provided.\n        xi (array-like): Damping ratio at different frequencies.  If xi, is provided, mu must also be provided.\n        w (array-like): MRE frequency for each gp/gpp or mu/xi value, must follow the same order.\n        tol (float, optional): Back calculation tolerance check. Defaults to 1.00e-3.\n\n    Raises:\n        ValueError: gp/gpp or mu/xi not provided\n        ValueError: number of inputs on each array do not match\n        ValueError: Mu or Xi back-calculation out of range\n\n    Returns:\n        Ginf (float): long-time shear modulus\n        G1 (float): short-time shear modulus\n        tau (float): short-time time constant\n        gp (float): Storage modulus\n        gpp (float): Loss modulus\n    \"\"\"\n\n    # check for valid input\n    first_set_valid = all(param is not None for param in [gp, gpp, w])\n    second_set_valid = all(param is not None for param in [mu, xi, w])\n\n    # Raise error if neither parameter set is complete\n    if not (first_set_valid or second_set_valid):\n        raise ValueError(\n            \"You must provide either (gp, gpp, w) or (mu, xi, w) as inputs\"\n        )\n\n    # check if all are array like\n    first_set_type = all(_is_array(o) for o in [gp, gpp, w])\n    second_set_type = all(_is_array(o) for o in [mu, xi, w])\n\n    if not (first_set_type or second_set_type):\n        raise ValueError(\"Unmatched number of values for input parameters\")\n\n    if second_set_type:\n        mu = np.asarray(mu)\n        xi = np.asarray(xi)\n\n    w = np.asarray(w)\n\n    # calculate complex modulus from stiffness and damping ratio (array)\n    if second_set_valid:\n        assert mu is not None, \"mu must be provided if xi is provided\"\n        assert xi is not None, \"xi must be provided if mu is provided\"\n\n        mu = np.abs(mu)\n        xi = np.abs(xi)\n\n        a = np.sqrt(1.0 + 4.0 * np.square(xi))\n\n        gp_array: np.ndarray = ((1.0 + a) * mu) / (2.0 * np.square(a))\n        gpp_array: np.ndarray = 2.0 * xi * gp_array\n        gmag_array: np.ndarray = np.sqrt(\n            np.square(gp_array) + np.square(gpp_array)\n        )\n\n        # back-calculate mu and xi to check calculation, raise error if they don't match\n        mu_bc = 2.0 * np.square(gmag_array) / (gp_array + gmag_array)\n        xi_bc = gpp_array / (2.0 * gp_array)\n\n        if np.sum((mu - mu_bc) ** 2) &gt;= tol:\n            raise ValueError(\n                f\"Error in mu back-calculation: mu = {mu}, mu_bc = {mu_bc}.\"\n            )\n        if np.sum((xi - xi_bc) ** 2) &gt;= tol:\n            raise ValueError(\n                f\"Error in xi back-calculation, xi = {xi}, xi_bc = {xi_bc}..\"\n            )\n\n    else:\n        assert gp is not None, \"gp must be provided if gpp is provided\"\n        assert gpp is not None, \"gpp must be provided if gp is provided\"\n\n        gp_array = np.asarray(gp)\n        gpp_array = np.asarray(gpp)\n\n    # calculate te prony series constants\n\n    Ginf, G1, tau = prony_series(gp_array, gpp_array, w)\n\n    return Ginf, G1, tau\n</code></pre>"},{"location":"api/#MRI2FE.MRE.calculate_prony.prony_series","title":"<code>prony_series(gp, gpp, w)</code>","text":"<p>Calculate the 1-term prony series constants for an equivalent complex shear modulus using least squares optimization</p> <p>Parameters:</p> Name Type Description Default <code>gp</code> <code>float</code> <p>Storage modulus</p> required <code>gpp</code> <code>float</code> <p>Loss modulus</p> required <code>w</code> <code>float</code> <p>Modulus frequency</p> required <p>Returns:</p> Name Type Description <code>Ginf</code> <code>float</code> <p>Long-time shear modulus</p> <code>G1</code> <code>float</code> <p>short-time shear modulus</p> <code>tau</code> <code>float</code> <p>time constant</p> Source code in <code>src/MRI2FE/MRE/calculate_prony.py</code> <pre><code>def prony_series(\n    gp: Union[float, np.ndarray],\n    gpp: Union[float, np.ndarray],\n    w: Union[float, np.ndarray],\n):\n    \"\"\"\n    Calculate the 1-term prony series constants for an equivalent complex shear modulus using least squares optimization\n\n    Arguments:\n        gp (float): Storage modulus\n        gpp (float): Loss modulus\n        w (float): Modulus frequency\n\n    Returns:\n        Ginf (float): Long-time shear modulus\n        G1 (float): short-time shear modulus\n        tau (float): time constant\n    \"\"\"\n\n    # Ensure all inputs are ndarrays for consistent handling\n    gp = np.asarray(gp)\n    gpp = np.asarray(gpp)\n    w = np.asarray(w)\n\n    # Check if we have scalar or vector inputs\n    is_scalar_input = gp.ndim == 0 and gpp.ndim == 0 and w.ndim == 0\n\n    # Initial guess for optimization variables [g1, g2, tau]\n    if is_scalar_input:\n        x0 = np.array([1.0, 1.0, 1.0 / w])\n    else:\n        x0 = np.array([1.0, 1.0, 1.0 / np.mean(w)])\n\n    # Bounds for variables (all non-negative)\n    bounds = [(0, None), (0, None), (0, None)]\n\n    # Objective function to minimize\n    def objective(x):\n        g1, g2, tau = x\n        # Calculate the expressions for gp and gpp\n        gpex = g1 + (g2 * w**2 * tau**2) / (1 + w**2 * tau**2)\n        gppex = (g2 * w * tau) / (1 + w**2 * tau**2)\n\n        # Return the sum of squared errors\n        return np.sum((gp - gpex) ** 2 + (gpp - gppex) ** 2)\n\n    # Constraint: gppex/gpex = gpp/gp\n    def constraint(x):\n        g1, g2, tau = x\n        gpex = g1 + (g2 * w**2 * tau**2) / (1 + w**2 * tau**2)\n        gppex = (g2 * w * tau) / (1 + w**2 * tau**2)\n\n        if gpex.any() == 0.0:\n            return np.mean(gppex) - np.mean(gpp / gp)\n        else:\n            return np.mean(gppex / gpex) - np.mean(gpp / gp)\n\n    # Define the constraint as a dictionary\n    cons = {\"type\": \"eq\", \"fun\": constraint}\n\n    # Solve the optimization problem\n    result = minimize(\n        objective,\n        x0,\n        method=\"SLSQP\",\n        bounds=bounds,\n        constraints=cons,\n        options={\"ftol\": 1e-10},\n    )\n\n    # Extract the optimized values\n    g1, g2, tau = result.x\n\n    return g1, g2, tau\n</code></pre>"},{"location":"api/#MRI2FE.MRE.map_MRE_to_mesh","title":"<code>MRI2FE.MRE.map_MRE_to_mesh(mdl, label_img, region_properties, target_region_id=4, label_background_id=0, region_prefix=None, imgout=None)</code>","text":"<p>Map MRE properties onto FE mesh and store associated material properties in the model material array</p> <p>Parameters:</p> Name Type Description Default <code>mdl</code> <code>FEModel</code> <p>FE model to map MRE regions onto</p> required <code>label_img</code> <code>ANTsImage</code> <p>MRI image with integer labels for each MRE region</p> required <code>region_properties</code> <code>List</code> <p>List of prony series properties for each MRE region</p> required <code>target_region_id</code> <code>int</code> <p>Target PID in the FE model to replace with segmented MRE IDs   .</p> <code>4</code> <code>label_background_id</code> <code>int</code> <p>Integer label in the label_img associated with the background. Defaults to 0.</p> <code>0</code> <code>region_prefix</code> <code>str</code> <p>name prefix for the new part assignment names</p> <code>None</code> <p>Raises:</p> Type Description <code>TypeError</code> <p>Input not the right type</p> <code>ValueError</code> <p>negative target region</p> <p>Returns:</p> Name Type Description <code>FEModel</code> <code>FEModel</code> <p>Model with updated PIDs for the target region and material properties added</p> Source code in <code>src/MRI2FE/MRE/MRE_mapping.py</code> <pre><code>def map_MRE_to_mesh(\n    mdl: FEModel,\n    label_img: ANTsImage,\n    region_properties: List,\n    target_region_id: int = 4,\n    label_background_id: int = 0,\n    region_prefix: Optional[str] = None,\n    imgout: Optional[str] = None,\n) -&gt; FEModel:\n    \"\"\"Map MRE properties onto FE mesh and store associated material properties in the model material array\n\n    Args:\n        mdl (FEModel): FE model to map MRE regions onto\n        label_img (ANTsImage): MRI image with integer labels for each MRE region\n        region_properties (List): List of prony series properties for each MRE region\n        target_region_id (int, optional): Target PID in the FE model to replace with segmented MRE IDs   .\n        label_background_id (int, optional): Integer label in the label_img associated with the background. Defaults to 0.\n        region_prefix (str, optional): name prefix for the new part assignment names\n\n    Raises:\n        TypeError: Input not the right type\n        ValueError: negative target region\n\n    Returns:\n        FEModel: Model with updated PIDs for the target region and material properties added\n    \"\"\"\n    if not isinstance(mdl, FEModel):\n        raise TypeError(\"mdl must be a FEModel object\")\n\n    if not isinstance(label_img, ANTsImage):\n        raise TypeError(\"map must be an ANTsImage object\")\n\n    if not isinstance(target_region_id, int):\n        raise TypeError(\"offset must be an integer\")\n    if target_region_id &lt; 0:\n        raise ValueError(\"offset must be non-negative\")\n\n    # check for centroids\n    if mdl.centroid_table is None:\n        mdl.update_centroids()\n        assert mdl.centroid_table is not None\n\n    label_img_long = spatial_map(label_img)\n\n    # find max ID in existing model to use as offset\n    max_id = np.max(mdl.element_table[:, 1])\n\n    # create filtered space map and centroids for ROI only\n    label_img_long_nobackground = label_img_long[\n        label_img_long[:, 3] != label_background_id\n    ]\n\n    # find elements and centroids within target label region\n    ect_region_mask = mdl.element_table[:, 1] == target_region_id\n\n    elcentroids_ROI = mdl.centroid_table[ect_region_mask, :]\n\n    # create KDTree\n    physical_space_tree = sp.KDTree(\n        label_img_long_nobackground[:, 0:3], leafsize=15\n    )\n\n    d, idx = physical_space_tree.query(elcentroids_ROI, k=1)\n    # calculate correct PID offset\n    if max_id == target_region_id:\n        offset = max_id - 1\n    else:\n        offset = max_id\n\n    new_pids = label_img_long_nobackground[idx, 3] + offset\n\n    mdl.element_table[ect_region_mask, 1] = new_pids\n\n    # map part IDs and material ids\n\n    for idx, mat in enumerate(region_properties):\n        if idx is not label_background_id:\n            mat_id = idx + offset\n\n            # create part\n            if region_prefix is not None:\n                mdl.part_info[str(mat_id)] = {\n                    \"name\": f\"{region_prefix}_{idx}\",\n                    \"constants\": [mat_id],\n                }\n            else:\n                mdl.part_info[str(mat_id)] = {\n                    \"name\": f\"{target_region_id}_{idx}\",\n                    \"constants\": [mat_id],\n                }\n\n            # create material\n            if region_prefix is not None:\n                mdl.material_info.append(\n                    {\n                        \"type\": \"KELVIN-MAXWELL_VISCOELASTIC\",\n                        \"name\": f\"{target_region_id}_{idx}\",\n                        \"ID\": mat_id,\n                        \"constants\": [0, 0] + list(mat),\n                    }\n                )\n            else:\n                mdl.material_info.append(\n                    {\n                        \"type\": \"KELVIN-MAXWELL_VISCOELASTIC\",\n                        \"ID\": mat_id,\n                        \"constants\": [0, 0] + list(mat),\n                    }\n                )\n\n    return mdl\n</code></pre>"},{"location":"api/#model-class-and-io","title":"Model class and I/O","text":""},{"location":"api/#MRI2FE.FEModel","title":"<code>MRI2FE.FEModel</code>","text":"<p>Model object storing the generated FE model.</p> Source code in <code>src/MRI2FE/models/femodel.py</code> <pre><code>class FEModel:\n    \"\"\"Model object storing the generated FE model.\"\"\"\n\n    def __init__(\n        self,\n        title: str = \"\",\n        source: str = \"\",\n        imgout: Optional[str] = None,\n        nodes: Optional[ArrayLike] = None,\n        elements: Optional[ArrayLike] = None,\n        parts: Optional[dict] = None,\n        materials: Optional[List[dict]] = None,\n        sections: Optional[List[dict]] = None,\n    ):\n        \"\"\"Initialize the FE model\n\n        Args:\n            title (str, optional): Name for model, will be inserted as solver deck title on output. Defaults to \"\".\n            source (str, optional): Source file for model, optional. Defaults to \"\".\n            imgout (str, optional): Directory to save validation images to.  Defaults to None.\n            nodes (Union[list, np.ndarray], optional): Array with shape (n,4) containing node ID, x, y, z coordinates. Defaults to None.\n            elements (Union[list, np.ndarray], optional): Array with shape (n,m+2) containing element ID, part/group ID, and m connected nodes. Defaults to None.\n            parts (dict, optional): Part definitions.  Dictionary keys are the part ID.  Each key is linked to a dictionary with entries \"name\" and \"constants\". Defaults to None.\n            materials (List[dict], optional): Material definitions.  List of dictionaries.  Each dictionary must contain the keys \"name\", \"ID\", and \"constants\". Defaults to None.\n            sections (List[dict], optional): Material section definitions.  List of dictionaries.  Each dictionary must contain the keys \"ID\" and \"constants\". Defaults to None.\n\n        Raises:\n            ValueError: Wrong input type.\n        \"\"\"\n        self.metadata = {\n            \"title\": title,\n            \"source\": source,\n            \"num_nodes\": 0,\n            \"num_elements\": 0,\n            \"imgout\": imgout,\n        }\n\n        self.centroid_table = None\n\n        # create node table - array of shape (n,4) where each column has the format: [node_id, x, y, z]\n        if nodes is not None:\n            if isinstance(nodes, list):\n                self.node_table: np.ndarray = np.array(nodes)\n            elif isinstance(nodes, np.ndarray):\n                self.node_table = nodes\n            else:\n                raise ValueError(\"Nodes must be a list or numpy array\")\n\n            self.metadata[\"num_nodes\"] = self.node_table.shape[0]\n        else:\n            self.node_table = np.array([])\n            self.metadata[\"num_nodes\"] = 0\n\n        # create element table - array of shape (n,m+2) where m is the number of nodes in the element type: [element_id, part_id, node1, node2, node3, node4...]\n        if elements is not None:\n            if isinstance(elements, np.ndarray):\n                self.element_table = elements\n            elif isinstance(elements, list):\n                self.element_table = np.array(elements)\n            else:\n                raise ValueError(\"Elements must be a list or numpy array\")\n            self.metadata[\"num_elements\"] = self.element_table.shape[0]\n        else:\n            self.element_table = np.array([])\n            self.metadata[\"num_elements\"] = 0\n\n        # create centroid table - List of centroids: [x,y,z]\n        self.centroid_table = None\n\n        # create part info - Dictionary with keys \"part id\" and dictionary of \"name\":str and \"constants\":list\n        if parts is not None:\n            if isinstance(parts, dict):\n                self.part_info = parts\n            else:\n                raise ValueError(\"Parts must be a dictionary\")\n        else:\n            self.part_info = {}\n\n        # create material info - List of Dictionaries with three entries: \"type\":str, \"ID\":int, and \"constants\":list[int,float]\n        if materials is not None:\n            if isinstance(materials, list):\n                self.material_info = materials\n            else:\n                raise ValueError(\"Materials must be a list of dictionaries\")\n        else:\n            self.material_info = []\n\n        # create section info - List of Dictionaries with two entries: \"ID\": str and \"constants\":list[int, float]\n        if sections is not None:\n            if isinstance(sections, list):\n                self.section_info = sections\n            else:\n                raise ValueError(\"Sections must be a list of dictionaries\")\n        else:\n            self.section_info = []\n\n    def add_nodes(\n        self,\n        node_id: Optional[int] = None,\n        x: Optional[float] = None,\n        y: Optional[float] = None,\n        z: Optional[float] = None,\n        node_array: Optional[ArrayLike] = None,\n        force_insert: bool = False,\n    ):\n        \"\"\"Add a node to the node table\n\n        Args:\n            node_id (int, optional): ID of the new node to add, must provide x-, y- and z- coordinates if specified. Defaults to None.\n            x (float, optional): x-coordinate of the node, must also provide y- and z-coordinates. Defaults to None.\n            y (float, optional): y-coordinate of the node, must also provide x- and z-coordinates. Defaults to None.\n            z (float, optional): z-coordinate of the node, must also provide x- and y-coordinates. Defaults to None.\n            node_array (np.ndarray, optional): (4,) array containing node_id,x,y,z coordinates. Defaults to None.\n            force_insert (bool, optional): Whether to overwrite existing node with the same ID. Defaults to False.\n\n        Raises:\n            ValueError: Wrong input type.\n            ValueError: Wrong array size.\n            ValueError: Node ID already exists and force_insert false.\n        \"\"\"\n        # check which input type is provided\n        if all(var is not None for var in [node_id, x, y, z]):\n            indiv_input = True\n            node_id_list = np.array([node_id])\n\n        elif node_array is not None:\n            indiv_input = False\n            node_array = np.atleast_2d(node_array)\n            node_id_list = node_array[:, 0]\n\n        else:\n            raise ValueError(\n                \"Must provide either (node_id,x,y,z) or node_array\"\n            )\n\n        node_array = np.asarray(node_array)\n        # check array dimensions match\n        if (\n            not indiv_input\n            and node_array is not None\n            and node_array.shape[1] != self.node_table.shape[1]\n        ):\n            raise ValueError(\n                \"Node array dimensions do not match node table dimensions\"\n            )\n\n        if not force_insert and self.node_table.size &gt; 0:\n            # check if node already in the table\n            node_table = np.atleast_2d(self.node_table)\n            node_table = node_table[:, 0]\n            matches = np.intersect1d(node_id_list, node_table)\n\n            if len(matches) &gt; 0:\n                raise ValueError(\n                    f\"The following inserted nodes have duplicate IDs: {matches}\"\n                )\n\n        # if node array is none, inserted nodes becomes array\n        if self.node_table.size == 0 and indiv_input:\n            self.node_table = np.array([node_id, x, y, z])\n            self.metadata[\"num_nodes\"] = 1\n\n        elif self.node_table.size == 0:\n            self.node_table = node_array\n            self.metadata[\"num_nodes\"] = node_array.shape[0]\n\n        # add nodes to node table\n        elif indiv_input:\n            self.node_table = np.row_stack(\n                (self.node_table, np.array([node_id, x, y, z]))\n            )\n\n            current_count = cast(int, self.metadata.get(\"num_nodes\", 0))\n            self.metadata[\"num_nodes\"] = current_count + 1\n        else:\n            assert node_array is not None\n            self.node_table = np.row_stack((self.node_table, node_array))\n\n            current_count = cast(int, self.metadata.get(\"num_nodes\", 0))\n            self.metadata[\"num_nodes\"] = current_count + node_array.shape[0]\n\n    def add_elements(\n        self,\n        element_id: Optional[int] = None,\n        part_id: Optional[int] = None,\n        nodes: Optional[list] = None,\n        element_array: Optional[np.ndarray] = None,\n        force_insert: bool = False,\n    ):\n        \"\"\"Add an element to the element table.\n\n        Args:\n            element_id (int, optional): Element ID, must also provide part_id and nodes if not None. Defaults to None.\n            part_id (int, optional): Connected part ID, must also provide element_id and nodes if not None. Defaults to None.\n            nodes (list, optional): Connected node IDs, must also provide element_id and part_id. Defaults to None.\n            element_array (np.ndarray, optional): Array of shape (n+2,) containing element_id, part_id, n connected node ids. Defaults to None.\n            force_insert (bool, optional): Whether to overwrite if element already exists with the same ID. Defaults to False.\n\n        Raises:\n            ValueError: Wrong input type.\n            ValueError: Input shape mismatch with element table.\n            ValueError: Element ID already exists and force_insert is False.\n        \"\"\"\n\n        if all(var is not None for var in [element_id, part_id, nodes]):\n            indiv_input = True\n            element_id_list = [element_id]\n\n        elif element_array is not None:\n            indiv_input = False\n\n            element_array = np.atleast_2d(element_array)\n            element_id_list = element_array[:, 0].tolist()\n\n        else:\n            raise ValueError(\n                \"Must provide either (element_id, part_id, nodes) or element_array\"\n            )\n\n        # check if array dimensions match\n        if (\n            not indiv_input\n            and element_array is not None\n            and not element_array.shape[1] == self.element_table.shape[1]\n        ):\n            raise ValueError(\n                \"Element array dimensions do not match self.element_table dimensions\"\n            )\n\n        # check if element already exists\n        if not force_insert and self.element_table.size &gt; 0:\n            # check if node already in the table\n            element_table = np.atleast_2d(self.element_table)\n            element_table = element_table[:, 0]\n            matches = np.intersect1d(np.array(element_id_list), element_table)\n\n            if len(matches) &gt; 0:\n                raise ValueError(\n                    f\"The following inserted nodes have duplicate IDs: {matches}\"\n                )\n\n        # if element array is none, inserted element becomes array\n        if self.element_table.size == 0 and indiv_input:\n            assert nodes is not None\n            self.element_table = np.array([element_id, part_id] + nodes)\n            self.metadata[\"num_elements\"] = 1\n\n        elif self.element_table.size == 0:\n            assert element_array is not None\n\n            self.element_table = element_array\n            self.metadata[\"num_elements\"] = element_array.shape[0]\n\n        elif indiv_input and nodes is not None:\n            row_insert = np.array([element_id, part_id] + nodes)\n            self.element_table = np.row_stack((self.element_table, row_insert))\n\n            current_count = cast(int, self.metadata.get(\"num_elements\", 0))\n            self.metadata[\"num_elements\"] = current_count + 1\n        elif element_array is not None:\n            self.element_table = np.row_stack(\n                (self.element_table, element_array)\n            )\n\n            current_count = cast(int, self.metadata.get(\"num_elements\", 0))\n            self.metadata[\"num_elements\"] = (\n                current_count + element_array.shape[0]\n            )\n\n    def update_centroids(self):\n        \"\"\"Update the centroid table with all elements in the element table.\"\"\"\n        if self.element_table.size &gt; 0:\n            node_dict = {\n                int(self.node_table[i, 0]): i\n                for i in range(len(self.node_table))\n            }\n            n_elements = len(self.element_table)\n            centroids = np.zeros((n_elements, 3))\n\n            for i, element in enumerate(self.element_table):\n                node_ids = np.unique(element[2:])\n                node_indices = [\n                    node_dict[int(node_id)] for node_id in node_ids\n                ]\n                centroids[i] = np.mean(\n                    self.node_table[node_indices, 1:], axis=0\n                )\n            self.centroid_table = centroids\n\n    def add_part(self, part_id: int, name: str, material_constants: list):\n        \"\"\"Add part information (e.g., material constants).\"\"\"\n        self.part_info[part_id] = {}\n        self.part_info[part_id][\"name\"] = name\n        self.part_info[part_id][\"constants\"] = material_constants\n\n    def get_part_info(self):\n        \"\"\"Return the part information.\"\"\"\n        return self.part_info\n\n    def __repr__(self):\n        \"\"\"String representation of the FEModel.\"\"\"\n        return (\n            f\"FEModel(title={self.metadata['title']}, \"\n            f\"source={self.metadata['source']}, \"\n            f\"num_nodes={self.metadata['num_nodes']}, \"\n            f\"num_elements={self.metadata['num_elements']})\"\n        )\n\n    def write_lsdyna(self, filename: str):\n        \"\"\"\n        Write FE model data to an LS-DYNA .k file.\n\n        Args:\n            filename (str): Output file path for the .k file.\n        \"\"\"\n        with open(filename, \"w\") as f:\n            f.write(\"*KEYWORD\\n\")\n            f.write(f\"*TITLE\\n{self.metadata['title']}\\n\")\n\n            # Write nodes\n            f.write(\"*NODE\\n\")\n            for row in self.node_table:\n                f.write(\n                    f\"{int(row[0]):8d}{row[1]:16.6f}{row[2]:16.6f}{row[3]:16.6f}\\n\"\n                )\n\n            # Write elements\n            f.write(\"*ELEMENT_SOLID\\n\")\n            for row in self.element_table:\n                f.write(\n                    f\"{int(row[0]):&gt;8d}{int(row[1]):&gt;8d}\\n\"\n                )  # eid and part id\n\n                # write element connectivity, padding to 10-node format\n                for i in range(2, len(row)):\n                    f.write(f\"{row[i]:&gt;8d}\")\n\n                # Pad with last valid node or a dummy valid node ID (ex. repeat last node)\n                last_node = row[-1]\n                for i in range(len(row), 10):\n                    f.write(f\"{last_node:&gt;8d}\")\n\n                # zero padding for n9 and n10\n                f.write(f\"{0:&gt;8d}{0:&gt;8d}\")\n\n                f.write(\"\\n\")\n\n            # Writing parts\n            for id, part in self.part_info.items():\n                f.write(\"*PART\\n\")\n                f.write(part[\"name\"] + \"\\n\")\n                part_insert = [0, 0, 0, 0, 0, 0, 0, 0]\n                part_insert[0] = int(id)\n                # update default part with all available information\n                for idx, item in enumerate(part[\"constants\"]):\n                    part_insert[idx + 1] = item\n\n                for item in part_insert:\n                    f.write(f\"{item:&gt;10d}\")\n                f.write(\"\\n\")\n\n            # Write solid sections\n            for sec in self.section_info:\n                f.write(\"*SECTION_SOLID\\n\")\n                secid = sec[\"ID\"]\n                elform = sec[\"constants\"][0]\n                aet = 0\n                if len(sec[\"constants\"]) &gt; 1:\n                    aet = sec[\"constants\"][1]\n                f.write(\n                    f\"{secid:&gt;10d}{elform:&gt;10d}{aet:10d}{0.0:&gt;40.1f}{0.0:&gt;10.1f}\\n\"\n                )\n\n            # Write materials\n            for mat in self.material_info:\n                mat_type = mat[\"type\"]\n                mat_id = mat[\"ID\"]\n                props = mat[\"constants\"]\n\n                # check if multi-line input card, raise error if yes\n                if len(props) &gt; 7:\n                    raise ValueError(\n                        f\"Error in material id {mat_id}: multi-line input cards not supported\"\n                    )\n\n                mat_insert = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n                mat_insert[0] = mat_id\n                for idx, item in enumerate(props):\n                    mat_insert[idx + 1] = item\n\n                if \"name\" in mat:\n                    f.write(f\"*MAT_{mat_type}_TITLE\\n\")\n                    f.write(f\"{mat['name']}\\n\")\n                else:\n                    f.write(f\"*MAT_{mat_type}\\n\")\n                for item in mat_insert:\n                    # convert from numpy types\n                    if hasattr(\n                        item, \"item\"\n                    ):  # numpy scalars have .item() method\n                        item = item.item()\n\n                    # check and write type\n                    if isinstance(item, int):\n                        f.write(f\"{item:&gt;10d}\")\n                    elif isinstance(item, float) and item == 0.0:\n                        f.write(f\"{0.0:&gt;10.1f}\")\n                    elif isinstance(item, float):\n                        f.write(f\"{item:&gt;10.2E}\")\n                    else:\n                        raise ValueError(\n                            f\"Unsupported type in material constants: {type(item)}\"\n                        )\n\n                f.write(\"\\n\")\n\n            # End of file\n            f.write(\"*END\\n\")\n\n    def from_meshio(\n        self,\n        mesh: Union[meshio.Mesh, str],\n        element_type: Literal[\"tetra\"] = \"tetra\",\n        region_names: Optional[List[str]] = None,\n    ):\n        \"\"\"Append mesh data from a meshio mesh object or file to the FEModel, offsetting IDs and\n        updating metadata.\n\n        Args:\n            mesh (meshio.Mesh, str): Mesh object or filepath to mesh file.\n            element_type (\"tetra\", optional): Element type to import. Only \"tetra\" is supported.\n            region_names (List[str], optional): Optional part names for each region. Defaults to None.\n\n        Raises:\n            ValueError: If the element type of the new mesh does not match the existing FEModel.\n            ValueError: If no elements of the specified type are found in the mesh.\n        \"\"\"\n        if isinstance(mesh, str):\n            mesh = meshio.read(mesh)\n\n        # Check element type compatibility\n        if self.element_table is not None and self.element_table.size &gt; 0:\n            # Assume all elements in self.element_table are of the same type\n            num_nodes_per_elem = self.element_table.shape[1] - 2\n            if element_type == \"tetra\" and num_nodes_per_elem != 4:\n                raise ValueError(\n                    \"Element type mismatch: existing elements are not tetrahedrons.\"\n                )\n\n        mesh_nodes = mesh.points\n        n_points = mesh_nodes.shape[0]\n        # Offset node IDs\n        max_node_id = (\n            int(np.max(self.node_table[:, 0]))\n            if self.node_table is not None and self.node_table.size &gt; 0\n            else 0\n        )\n        nids = np.arange(1, n_points + 1) + max_node_id\n        new_nodes = np.column_stack((nids, mesh_nodes))\n\n        # Find an element type in cells\n        connectivity_index = None\n        node_connectivity = None\n        for idx, item in enumerate(mesh.cells):\n            if item.type == element_type:\n                # Map 0-based mesh indices to our new node IDs\n                node_connectivity = nids[item.data]\n                connectivity_index = idx\n                break\n        if node_connectivity is None:\n            raise ValueError(\n                f\"Element type {element_type} not found in mesh cells\"\n            )\n\n        n_elements = node_connectivity.shape[0]\n        max_elem_id = (\n            int(np.max(self.element_table[:, 0]))\n            if self.element_table is not None and self.element_table.size &gt; 0\n            else 0\n        )\n        eids = np.arange(1, n_elements + 1) + max_elem_id\n\n        # Offset part IDs\n        if \"medit:ref\" not in mesh.cell_data:\n            raise ValueError(\n                \"Mesh must contain 'medit:ref' cell data for part IDs\"\n            )\n\n        pid = mesh.cell_data[\"medit:ref\"][connectivity_index]\n        max_part_id = (\n            max([int(k) for k in self.part_info.keys()])\n            if self.part_info\n            else 0\n        )\n        pid_offset = max_part_id\n\n        new_pid = pid + pid_offset\n        new_elements = np.column_stack((eids, new_pid, node_connectivity))\n\n        # Filter pid zero\n        mask = new_pid &gt; 0\n        new_elements = new_elements[mask, :]\n        new_pid_filtered = new_pid[mask]\n\n        # all nodes are used\n        new_nodes = new_nodes\n\n        # Update part_info - only for parts that have elements (after filtering)\n        for idx, id in enumerate(np.unique(new_pid_filtered)):\n            if region_names is not None and idx &lt; len(region_names):\n                self.part_info[str(id)] = {\n                    \"name\": region_names[idx],\n                    \"constants\": [],\n                }\n            else:\n                self.part_info[str(id)] = {\"name\": str(id), \"constants\": []}\n\n        # Link node and element tables\n        if self.node_table is not None and self.node_table.size &gt; 0:\n            self.node_table = np.row_stack((self.node_table, new_nodes))\n        else:\n            self.node_table = new_nodes\n\n        if self.element_table is not None and self.element_table.size &gt; 0:\n            self.element_table = np.row_stack(\n                (self.element_table, new_elements)\n            )\n        else:\n            self.element_table = new_elements\n\n        # Update metadata\n        self.metadata[\"num_nodes\"] = self.node_table.shape[0]\n        self.metadata[\"num_elements\"] = self.element_table.shape[0]\n        if \"source\" in self.metadata and self.metadata[\"source\"]:\n            self.metadata[\"source\"] = str(self.metadata[\"source\"]) + (\n                f\", meshio:{getattr(mesh, 'filename', 'unknown')}\"\n            )\n        else:\n            self.metadata[\"source\"] = (\n                f\"meshio:{getattr(mesh, 'filename', 'unknown')}\"\n            )\n</code></pre>"},{"location":"api/#MRI2FE.FEModel.__init__","title":"<code>__init__(title='', source='', imgout=None, nodes=None, elements=None, parts=None, materials=None, sections=None)</code>","text":"<p>Initialize the FE model</p> <p>Parameters:</p> Name Type Description Default <code>title</code> <code>str</code> <p>Name for model, will be inserted as solver deck title on output. Defaults to \"\".</p> <code>''</code> <code>source</code> <code>str</code> <p>Source file for model, optional. Defaults to \"\".</p> <code>''</code> <code>imgout</code> <code>str</code> <p>Directory to save validation images to.  Defaults to None.</p> <code>None</code> <code>nodes</code> <code>Union[list, ndarray]</code> <p>Array with shape (n,4) containing node ID, x, y, z coordinates. Defaults to None.</p> <code>None</code> <code>elements</code> <code>Union[list, ndarray]</code> <p>Array with shape (n,m+2) containing element ID, part/group ID, and m connected nodes. Defaults to None.</p> <code>None</code> <code>parts</code> <code>dict</code> <p>Part definitions.  Dictionary keys are the part ID.  Each key is linked to a dictionary with entries \"name\" and \"constants\". Defaults to None.</p> <code>None</code> <code>materials</code> <code>List[dict]</code> <p>Material definitions.  List of dictionaries.  Each dictionary must contain the keys \"name\", \"ID\", and \"constants\". Defaults to None.</p> <code>None</code> <code>sections</code> <code>List[dict]</code> <p>Material section definitions.  List of dictionaries.  Each dictionary must contain the keys \"ID\" and \"constants\". Defaults to None.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>Wrong input type.</p> Source code in <code>src/MRI2FE/models/femodel.py</code> <pre><code>def __init__(\n    self,\n    title: str = \"\",\n    source: str = \"\",\n    imgout: Optional[str] = None,\n    nodes: Optional[ArrayLike] = None,\n    elements: Optional[ArrayLike] = None,\n    parts: Optional[dict] = None,\n    materials: Optional[List[dict]] = None,\n    sections: Optional[List[dict]] = None,\n):\n    \"\"\"Initialize the FE model\n\n    Args:\n        title (str, optional): Name for model, will be inserted as solver deck title on output. Defaults to \"\".\n        source (str, optional): Source file for model, optional. Defaults to \"\".\n        imgout (str, optional): Directory to save validation images to.  Defaults to None.\n        nodes (Union[list, np.ndarray], optional): Array with shape (n,4) containing node ID, x, y, z coordinates. Defaults to None.\n        elements (Union[list, np.ndarray], optional): Array with shape (n,m+2) containing element ID, part/group ID, and m connected nodes. Defaults to None.\n        parts (dict, optional): Part definitions.  Dictionary keys are the part ID.  Each key is linked to a dictionary with entries \"name\" and \"constants\". Defaults to None.\n        materials (List[dict], optional): Material definitions.  List of dictionaries.  Each dictionary must contain the keys \"name\", \"ID\", and \"constants\". Defaults to None.\n        sections (List[dict], optional): Material section definitions.  List of dictionaries.  Each dictionary must contain the keys \"ID\" and \"constants\". Defaults to None.\n\n    Raises:\n        ValueError: Wrong input type.\n    \"\"\"\n    self.metadata = {\n        \"title\": title,\n        \"source\": source,\n        \"num_nodes\": 0,\n        \"num_elements\": 0,\n        \"imgout\": imgout,\n    }\n\n    self.centroid_table = None\n\n    # create node table - array of shape (n,4) where each column has the format: [node_id, x, y, z]\n    if nodes is not None:\n        if isinstance(nodes, list):\n            self.node_table: np.ndarray = np.array(nodes)\n        elif isinstance(nodes, np.ndarray):\n            self.node_table = nodes\n        else:\n            raise ValueError(\"Nodes must be a list or numpy array\")\n\n        self.metadata[\"num_nodes\"] = self.node_table.shape[0]\n    else:\n        self.node_table = np.array([])\n        self.metadata[\"num_nodes\"] = 0\n\n    # create element table - array of shape (n,m+2) where m is the number of nodes in the element type: [element_id, part_id, node1, node2, node3, node4...]\n    if elements is not None:\n        if isinstance(elements, np.ndarray):\n            self.element_table = elements\n        elif isinstance(elements, list):\n            self.element_table = np.array(elements)\n        else:\n            raise ValueError(\"Elements must be a list or numpy array\")\n        self.metadata[\"num_elements\"] = self.element_table.shape[0]\n    else:\n        self.element_table = np.array([])\n        self.metadata[\"num_elements\"] = 0\n\n    # create centroid table - List of centroids: [x,y,z]\n    self.centroid_table = None\n\n    # create part info - Dictionary with keys \"part id\" and dictionary of \"name\":str and \"constants\":list\n    if parts is not None:\n        if isinstance(parts, dict):\n            self.part_info = parts\n        else:\n            raise ValueError(\"Parts must be a dictionary\")\n    else:\n        self.part_info = {}\n\n    # create material info - List of Dictionaries with three entries: \"type\":str, \"ID\":int, and \"constants\":list[int,float]\n    if materials is not None:\n        if isinstance(materials, list):\n            self.material_info = materials\n        else:\n            raise ValueError(\"Materials must be a list of dictionaries\")\n    else:\n        self.material_info = []\n\n    # create section info - List of Dictionaries with two entries: \"ID\": str and \"constants\":list[int, float]\n    if sections is not None:\n        if isinstance(sections, list):\n            self.section_info = sections\n        else:\n            raise ValueError(\"Sections must be a list of dictionaries\")\n    else:\n        self.section_info = []\n</code></pre>"},{"location":"api/#MRI2FE.FEModel.__repr__","title":"<code>__repr__()</code>","text":"<p>String representation of the FEModel.</p> Source code in <code>src/MRI2FE/models/femodel.py</code> <pre><code>def __repr__(self):\n    \"\"\"String representation of the FEModel.\"\"\"\n    return (\n        f\"FEModel(title={self.metadata['title']}, \"\n        f\"source={self.metadata['source']}, \"\n        f\"num_nodes={self.metadata['num_nodes']}, \"\n        f\"num_elements={self.metadata['num_elements']})\"\n    )\n</code></pre>"},{"location":"api/#MRI2FE.FEModel.add_elements","title":"<code>add_elements(element_id=None, part_id=None, nodes=None, element_array=None, force_insert=False)</code>","text":"<p>Add an element to the element table.</p> <p>Parameters:</p> Name Type Description Default <code>element_id</code> <code>int</code> <p>Element ID, must also provide part_id and nodes if not None. Defaults to None.</p> <code>None</code> <code>part_id</code> <code>int</code> <p>Connected part ID, must also provide element_id and nodes if not None. Defaults to None.</p> <code>None</code> <code>nodes</code> <code>list</code> <p>Connected node IDs, must also provide element_id and part_id. Defaults to None.</p> <code>None</code> <code>element_array</code> <code>ndarray</code> <p>Array of shape (n+2,) containing element_id, part_id, n connected node ids. Defaults to None.</p> <code>None</code> <code>force_insert</code> <code>bool</code> <p>Whether to overwrite if element already exists with the same ID. Defaults to False.</p> <code>False</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>Wrong input type.</p> <code>ValueError</code> <p>Input shape mismatch with element table.</p> <code>ValueError</code> <p>Element ID already exists and force_insert is False.</p> Source code in <code>src/MRI2FE/models/femodel.py</code> <pre><code>def add_elements(\n    self,\n    element_id: Optional[int] = None,\n    part_id: Optional[int] = None,\n    nodes: Optional[list] = None,\n    element_array: Optional[np.ndarray] = None,\n    force_insert: bool = False,\n):\n    \"\"\"Add an element to the element table.\n\n    Args:\n        element_id (int, optional): Element ID, must also provide part_id and nodes if not None. Defaults to None.\n        part_id (int, optional): Connected part ID, must also provide element_id and nodes if not None. Defaults to None.\n        nodes (list, optional): Connected node IDs, must also provide element_id and part_id. Defaults to None.\n        element_array (np.ndarray, optional): Array of shape (n+2,) containing element_id, part_id, n connected node ids. Defaults to None.\n        force_insert (bool, optional): Whether to overwrite if element already exists with the same ID. Defaults to False.\n\n    Raises:\n        ValueError: Wrong input type.\n        ValueError: Input shape mismatch with element table.\n        ValueError: Element ID already exists and force_insert is False.\n    \"\"\"\n\n    if all(var is not None for var in [element_id, part_id, nodes]):\n        indiv_input = True\n        element_id_list = [element_id]\n\n    elif element_array is not None:\n        indiv_input = False\n\n        element_array = np.atleast_2d(element_array)\n        element_id_list = element_array[:, 0].tolist()\n\n    else:\n        raise ValueError(\n            \"Must provide either (element_id, part_id, nodes) or element_array\"\n        )\n\n    # check if array dimensions match\n    if (\n        not indiv_input\n        and element_array is not None\n        and not element_array.shape[1] == self.element_table.shape[1]\n    ):\n        raise ValueError(\n            \"Element array dimensions do not match self.element_table dimensions\"\n        )\n\n    # check if element already exists\n    if not force_insert and self.element_table.size &gt; 0:\n        # check if node already in the table\n        element_table = np.atleast_2d(self.element_table)\n        element_table = element_table[:, 0]\n        matches = np.intersect1d(np.array(element_id_list), element_table)\n\n        if len(matches) &gt; 0:\n            raise ValueError(\n                f\"The following inserted nodes have duplicate IDs: {matches}\"\n            )\n\n    # if element array is none, inserted element becomes array\n    if self.element_table.size == 0 and indiv_input:\n        assert nodes is not None\n        self.element_table = np.array([element_id, part_id] + nodes)\n        self.metadata[\"num_elements\"] = 1\n\n    elif self.element_table.size == 0:\n        assert element_array is not None\n\n        self.element_table = element_array\n        self.metadata[\"num_elements\"] = element_array.shape[0]\n\n    elif indiv_input and nodes is not None:\n        row_insert = np.array([element_id, part_id] + nodes)\n        self.element_table = np.row_stack((self.element_table, row_insert))\n\n        current_count = cast(int, self.metadata.get(\"num_elements\", 0))\n        self.metadata[\"num_elements\"] = current_count + 1\n    elif element_array is not None:\n        self.element_table = np.row_stack(\n            (self.element_table, element_array)\n        )\n\n        current_count = cast(int, self.metadata.get(\"num_elements\", 0))\n        self.metadata[\"num_elements\"] = (\n            current_count + element_array.shape[0]\n        )\n</code></pre>"},{"location":"api/#MRI2FE.FEModel.add_nodes","title":"<code>add_nodes(node_id=None, x=None, y=None, z=None, node_array=None, force_insert=False)</code>","text":"<p>Add a node to the node table</p> <p>Parameters:</p> Name Type Description Default <code>node_id</code> <code>int</code> <p>ID of the new node to add, must provide x-, y- and z- coordinates if specified. Defaults to None.</p> <code>None</code> <code>x</code> <code>float</code> <p>x-coordinate of the node, must also provide y- and z-coordinates. Defaults to None.</p> <code>None</code> <code>y</code> <code>float</code> <p>y-coordinate of the node, must also provide x- and z-coordinates. Defaults to None.</p> <code>None</code> <code>z</code> <code>float</code> <p>z-coordinate of the node, must also provide x- and y-coordinates. Defaults to None.</p> <code>None</code> <code>node_array</code> <code>ndarray</code> <p>(4,) array containing node_id,x,y,z coordinates. Defaults to None.</p> <code>None</code> <code>force_insert</code> <code>bool</code> <p>Whether to overwrite existing node with the same ID. Defaults to False.</p> <code>False</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>Wrong input type.</p> <code>ValueError</code> <p>Wrong array size.</p> <code>ValueError</code> <p>Node ID already exists and force_insert false.</p> Source code in <code>src/MRI2FE/models/femodel.py</code> <pre><code>def add_nodes(\n    self,\n    node_id: Optional[int] = None,\n    x: Optional[float] = None,\n    y: Optional[float] = None,\n    z: Optional[float] = None,\n    node_array: Optional[ArrayLike] = None,\n    force_insert: bool = False,\n):\n    \"\"\"Add a node to the node table\n\n    Args:\n        node_id (int, optional): ID of the new node to add, must provide x-, y- and z- coordinates if specified. Defaults to None.\n        x (float, optional): x-coordinate of the node, must also provide y- and z-coordinates. Defaults to None.\n        y (float, optional): y-coordinate of the node, must also provide x- and z-coordinates. Defaults to None.\n        z (float, optional): z-coordinate of the node, must also provide x- and y-coordinates. Defaults to None.\n        node_array (np.ndarray, optional): (4,) array containing node_id,x,y,z coordinates. Defaults to None.\n        force_insert (bool, optional): Whether to overwrite existing node with the same ID. Defaults to False.\n\n    Raises:\n        ValueError: Wrong input type.\n        ValueError: Wrong array size.\n        ValueError: Node ID already exists and force_insert false.\n    \"\"\"\n    # check which input type is provided\n    if all(var is not None for var in [node_id, x, y, z]):\n        indiv_input = True\n        node_id_list = np.array([node_id])\n\n    elif node_array is not None:\n        indiv_input = False\n        node_array = np.atleast_2d(node_array)\n        node_id_list = node_array[:, 0]\n\n    else:\n        raise ValueError(\n            \"Must provide either (node_id,x,y,z) or node_array\"\n        )\n\n    node_array = np.asarray(node_array)\n    # check array dimensions match\n    if (\n        not indiv_input\n        and node_array is not None\n        and node_array.shape[1] != self.node_table.shape[1]\n    ):\n        raise ValueError(\n            \"Node array dimensions do not match node table dimensions\"\n        )\n\n    if not force_insert and self.node_table.size &gt; 0:\n        # check if node already in the table\n        node_table = np.atleast_2d(self.node_table)\n        node_table = node_table[:, 0]\n        matches = np.intersect1d(node_id_list, node_table)\n\n        if len(matches) &gt; 0:\n            raise ValueError(\n                f\"The following inserted nodes have duplicate IDs: {matches}\"\n            )\n\n    # if node array is none, inserted nodes becomes array\n    if self.node_table.size == 0 and indiv_input:\n        self.node_table = np.array([node_id, x, y, z])\n        self.metadata[\"num_nodes\"] = 1\n\n    elif self.node_table.size == 0:\n        self.node_table = node_array\n        self.metadata[\"num_nodes\"] = node_array.shape[0]\n\n    # add nodes to node table\n    elif indiv_input:\n        self.node_table = np.row_stack(\n            (self.node_table, np.array([node_id, x, y, z]))\n        )\n\n        current_count = cast(int, self.metadata.get(\"num_nodes\", 0))\n        self.metadata[\"num_nodes\"] = current_count + 1\n    else:\n        assert node_array is not None\n        self.node_table = np.row_stack((self.node_table, node_array))\n\n        current_count = cast(int, self.metadata.get(\"num_nodes\", 0))\n        self.metadata[\"num_nodes\"] = current_count + node_array.shape[0]\n</code></pre>"},{"location":"api/#MRI2FE.FEModel.add_part","title":"<code>add_part(part_id, name, material_constants)</code>","text":"<p>Add part information (e.g., material constants).</p> Source code in <code>src/MRI2FE/models/femodel.py</code> <pre><code>def add_part(self, part_id: int, name: str, material_constants: list):\n    \"\"\"Add part information (e.g., material constants).\"\"\"\n    self.part_info[part_id] = {}\n    self.part_info[part_id][\"name\"] = name\n    self.part_info[part_id][\"constants\"] = material_constants\n</code></pre>"},{"location":"api/#MRI2FE.FEModel.from_meshio","title":"<code>from_meshio(mesh, element_type='tetra', region_names=None)</code>","text":"<p>Append mesh data from a meshio mesh object or file to the FEModel, offsetting IDs and updating metadata.</p> <p>Parameters:</p> Name Type Description Default <code>mesh</code> <code>(Mesh, str)</code> <p>Mesh object or filepath to mesh file.</p> required <code>element_type</code> <code>tetra</code> <p>Element type to import. Only \"tetra\" is supported.</p> <code>'tetra'</code> <code>region_names</code> <code>List[str]</code> <p>Optional part names for each region. Defaults to None.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the element type of the new mesh does not match the existing FEModel.</p> <code>ValueError</code> <p>If no elements of the specified type are found in the mesh.</p> Source code in <code>src/MRI2FE/models/femodel.py</code> <pre><code>def from_meshio(\n    self,\n    mesh: Union[meshio.Mesh, str],\n    element_type: Literal[\"tetra\"] = \"tetra\",\n    region_names: Optional[List[str]] = None,\n):\n    \"\"\"Append mesh data from a meshio mesh object or file to the FEModel, offsetting IDs and\n    updating metadata.\n\n    Args:\n        mesh (meshio.Mesh, str): Mesh object or filepath to mesh file.\n        element_type (\"tetra\", optional): Element type to import. Only \"tetra\" is supported.\n        region_names (List[str], optional): Optional part names for each region. Defaults to None.\n\n    Raises:\n        ValueError: If the element type of the new mesh does not match the existing FEModel.\n        ValueError: If no elements of the specified type are found in the mesh.\n    \"\"\"\n    if isinstance(mesh, str):\n        mesh = meshio.read(mesh)\n\n    # Check element type compatibility\n    if self.element_table is not None and self.element_table.size &gt; 0:\n        # Assume all elements in self.element_table are of the same type\n        num_nodes_per_elem = self.element_table.shape[1] - 2\n        if element_type == \"tetra\" and num_nodes_per_elem != 4:\n            raise ValueError(\n                \"Element type mismatch: existing elements are not tetrahedrons.\"\n            )\n\n    mesh_nodes = mesh.points\n    n_points = mesh_nodes.shape[0]\n    # Offset node IDs\n    max_node_id = (\n        int(np.max(self.node_table[:, 0]))\n        if self.node_table is not None and self.node_table.size &gt; 0\n        else 0\n    )\n    nids = np.arange(1, n_points + 1) + max_node_id\n    new_nodes = np.column_stack((nids, mesh_nodes))\n\n    # Find an element type in cells\n    connectivity_index = None\n    node_connectivity = None\n    for idx, item in enumerate(mesh.cells):\n        if item.type == element_type:\n            # Map 0-based mesh indices to our new node IDs\n            node_connectivity = nids[item.data]\n            connectivity_index = idx\n            break\n    if node_connectivity is None:\n        raise ValueError(\n            f\"Element type {element_type} not found in mesh cells\"\n        )\n\n    n_elements = node_connectivity.shape[0]\n    max_elem_id = (\n        int(np.max(self.element_table[:, 0]))\n        if self.element_table is not None and self.element_table.size &gt; 0\n        else 0\n    )\n    eids = np.arange(1, n_elements + 1) + max_elem_id\n\n    # Offset part IDs\n    if \"medit:ref\" not in mesh.cell_data:\n        raise ValueError(\n            \"Mesh must contain 'medit:ref' cell data for part IDs\"\n        )\n\n    pid = mesh.cell_data[\"medit:ref\"][connectivity_index]\n    max_part_id = (\n        max([int(k) for k in self.part_info.keys()])\n        if self.part_info\n        else 0\n    )\n    pid_offset = max_part_id\n\n    new_pid = pid + pid_offset\n    new_elements = np.column_stack((eids, new_pid, node_connectivity))\n\n    # Filter pid zero\n    mask = new_pid &gt; 0\n    new_elements = new_elements[mask, :]\n    new_pid_filtered = new_pid[mask]\n\n    # all nodes are used\n    new_nodes = new_nodes\n\n    # Update part_info - only for parts that have elements (after filtering)\n    for idx, id in enumerate(np.unique(new_pid_filtered)):\n        if region_names is not None and idx &lt; len(region_names):\n            self.part_info[str(id)] = {\n                \"name\": region_names[idx],\n                \"constants\": [],\n            }\n        else:\n            self.part_info[str(id)] = {\"name\": str(id), \"constants\": []}\n\n    # Link node and element tables\n    if self.node_table is not None and self.node_table.size &gt; 0:\n        self.node_table = np.row_stack((self.node_table, new_nodes))\n    else:\n        self.node_table = new_nodes\n\n    if self.element_table is not None and self.element_table.size &gt; 0:\n        self.element_table = np.row_stack(\n            (self.element_table, new_elements)\n        )\n    else:\n        self.element_table = new_elements\n\n    # Update metadata\n    self.metadata[\"num_nodes\"] = self.node_table.shape[0]\n    self.metadata[\"num_elements\"] = self.element_table.shape[0]\n    if \"source\" in self.metadata and self.metadata[\"source\"]:\n        self.metadata[\"source\"] = str(self.metadata[\"source\"]) + (\n            f\", meshio:{getattr(mesh, 'filename', 'unknown')}\"\n        )\n    else:\n        self.metadata[\"source\"] = (\n            f\"meshio:{getattr(mesh, 'filename', 'unknown')}\"\n        )\n</code></pre>"},{"location":"api/#MRI2FE.FEModel.get_part_info","title":"<code>get_part_info()</code>","text":"<p>Return the part information.</p> Source code in <code>src/MRI2FE/models/femodel.py</code> <pre><code>def get_part_info(self):\n    \"\"\"Return the part information.\"\"\"\n    return self.part_info\n</code></pre>"},{"location":"api/#MRI2FE.FEModel.update_centroids","title":"<code>update_centroids()</code>","text":"<p>Update the centroid table with all elements in the element table.</p> Source code in <code>src/MRI2FE/models/femodel.py</code> <pre><code>def update_centroids(self):\n    \"\"\"Update the centroid table with all elements in the element table.\"\"\"\n    if self.element_table.size &gt; 0:\n        node_dict = {\n            int(self.node_table[i, 0]): i\n            for i in range(len(self.node_table))\n        }\n        n_elements = len(self.element_table)\n        centroids = np.zeros((n_elements, 3))\n\n        for i, element in enumerate(self.element_table):\n            node_ids = np.unique(element[2:])\n            node_indices = [\n                node_dict[int(node_id)] for node_id in node_ids\n            ]\n            centroids[i] = np.mean(\n                self.node_table[node_indices, 1:], axis=0\n            )\n        self.centroid_table = centroids\n</code></pre>"},{"location":"api/#MRI2FE.FEModel.write_lsdyna","title":"<code>write_lsdyna(filename)</code>","text":"<p>Write FE model data to an LS-DYNA .k file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Output file path for the .k file.</p> required Source code in <code>src/MRI2FE/models/femodel.py</code> <pre><code>def write_lsdyna(self, filename: str):\n    \"\"\"\n    Write FE model data to an LS-DYNA .k file.\n\n    Args:\n        filename (str): Output file path for the .k file.\n    \"\"\"\n    with open(filename, \"w\") as f:\n        f.write(\"*KEYWORD\\n\")\n        f.write(f\"*TITLE\\n{self.metadata['title']}\\n\")\n\n        # Write nodes\n        f.write(\"*NODE\\n\")\n        for row in self.node_table:\n            f.write(\n                f\"{int(row[0]):8d}{row[1]:16.6f}{row[2]:16.6f}{row[3]:16.6f}\\n\"\n            )\n\n        # Write elements\n        f.write(\"*ELEMENT_SOLID\\n\")\n        for row in self.element_table:\n            f.write(\n                f\"{int(row[0]):&gt;8d}{int(row[1]):&gt;8d}\\n\"\n            )  # eid and part id\n\n            # write element connectivity, padding to 10-node format\n            for i in range(2, len(row)):\n                f.write(f\"{row[i]:&gt;8d}\")\n\n            # Pad with last valid node or a dummy valid node ID (ex. repeat last node)\n            last_node = row[-1]\n            for i in range(len(row), 10):\n                f.write(f\"{last_node:&gt;8d}\")\n\n            # zero padding for n9 and n10\n            f.write(f\"{0:&gt;8d}{0:&gt;8d}\")\n\n            f.write(\"\\n\")\n\n        # Writing parts\n        for id, part in self.part_info.items():\n            f.write(\"*PART\\n\")\n            f.write(part[\"name\"] + \"\\n\")\n            part_insert = [0, 0, 0, 0, 0, 0, 0, 0]\n            part_insert[0] = int(id)\n            # update default part with all available information\n            for idx, item in enumerate(part[\"constants\"]):\n                part_insert[idx + 1] = item\n\n            for item in part_insert:\n                f.write(f\"{item:&gt;10d}\")\n            f.write(\"\\n\")\n\n        # Write solid sections\n        for sec in self.section_info:\n            f.write(\"*SECTION_SOLID\\n\")\n            secid = sec[\"ID\"]\n            elform = sec[\"constants\"][0]\n            aet = 0\n            if len(sec[\"constants\"]) &gt; 1:\n                aet = sec[\"constants\"][1]\n            f.write(\n                f\"{secid:&gt;10d}{elform:&gt;10d}{aet:10d}{0.0:&gt;40.1f}{0.0:&gt;10.1f}\\n\"\n            )\n\n        # Write materials\n        for mat in self.material_info:\n            mat_type = mat[\"type\"]\n            mat_id = mat[\"ID\"]\n            props = mat[\"constants\"]\n\n            # check if multi-line input card, raise error if yes\n            if len(props) &gt; 7:\n                raise ValueError(\n                    f\"Error in material id {mat_id}: multi-line input cards not supported\"\n                )\n\n            mat_insert = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n            mat_insert[0] = mat_id\n            for idx, item in enumerate(props):\n                mat_insert[idx + 1] = item\n\n            if \"name\" in mat:\n                f.write(f\"*MAT_{mat_type}_TITLE\\n\")\n                f.write(f\"{mat['name']}\\n\")\n            else:\n                f.write(f\"*MAT_{mat_type}\\n\")\n            for item in mat_insert:\n                # convert from numpy types\n                if hasattr(\n                    item, \"item\"\n                ):  # numpy scalars have .item() method\n                    item = item.item()\n\n                # check and write type\n                if isinstance(item, int):\n                    f.write(f\"{item:&gt;10d}\")\n                elif isinstance(item, float) and item == 0.0:\n                    f.write(f\"{0.0:&gt;10.1f}\")\n                elif isinstance(item, float):\n                    f.write(f\"{item:&gt;10.2E}\")\n                else:\n                    raise ValueError(\n                        f\"Unsupported type in material constants: {type(item)}\"\n                    )\n\n            f.write(\"\\n\")\n\n        # End of file\n        f.write(\"*END\\n\")\n</code></pre>"},{"location":"api/#utilities","title":"Utilities","text":""},{"location":"api/#MRI2FE.COM_align","title":"<code>MRI2FE.COM_align(fixed, moving, fixed_mask=None, moving_mask=None)</code>","text":"<p>Align the centers of mass of two point clouds, operating either on the entire point cloud or on a masked region.</p> <p>Parameters:</p> Name Type Description Default <code>fixed</code> <code>ndarray</code> <p>Reference point cloud to be aligned to.</p> required <code>moving</code> <code>ndarray</code> <p>Point cloud to align with fixed cloud.</p> required <code>fixed_mask</code> <code>ndarray</code> <p>Fixed point cloud subset to define COM by. Defaults to None.</p> <code>None</code> <code>moving_mask</code> <code>ndarray</code> <p>Moving point cloud subset to define COM by. Defaults to None.</p> <code>None</code> <p>Raises:</p> Type Description <code>TypeError</code> <p>If inputs are not numpy arrays when provided</p> <code>ValueError</code> <p>If required inputs are None or have invalid dimensions</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: moving point cloud rigidly aligned to the fixed point cloud COM</p> Source code in <code>src/MRI2FE/utilities.py</code> <pre><code>def COM_align(\n    fixed: np.ndarray,\n    moving: np.ndarray,\n    fixed_mask: Optional[np.ndarray] = None,\n    moving_mask: Optional[np.ndarray] = None,\n) -&gt; np.ndarray:\n    \"\"\"Align the centers of mass of two point clouds, operating either on the entire point cloud or on a masked region.\n\n    Args:\n        fixed (np.ndarray): Reference point cloud to be aligned to.\n        moving (np.ndarray): Point cloud to align with fixed cloud.\n        fixed_mask (np.ndarray, optional): Fixed point cloud subset to define COM by. Defaults to None.\n        moving_mask (np.ndarray, optional): Moving point cloud subset to define COM by. Defaults to None.\n\n    Raises:\n        TypeError: If inputs are not numpy arrays when provided\n        ValueError: If required inputs are None or have invalid dimensions\n\n    Returns:\n        np.ndarray: moving point cloud rigidly aligned to the fixed point cloud COM\n    \"\"\"\n    # Validate required inputs are not None\n    if fixed is None:\n        raise ValueError(\"fixed cannot be None\")\n    if moving is None:\n        raise ValueError(\"moving cannot be None\")\n\n    # confirm numpy array input and validate dimensions\n    fixed = np.asarray(fixed)\n    if len(fixed.shape) != 2:\n        raise ValueError(\"fixed must be a 2D array\")\n\n    moving = np.asarray(moving)\n    if len(moving.shape) != 2:\n        raise ValueError(\"moving must be a 2D array\")\n\n    # Validate matching dimensions\n    if fixed.shape[1] != moving.shape[1]:\n        raise ValueError(\n            \"fixed and moving must have the same number of dimensions\"\n        )\n\n    # Validate masks if provided\n    if fixed_mask is not None:\n        fixed_mask = np.asarray(fixed_mask)\n        if len(fixed_mask.shape) != 2:\n            raise ValueError(\"fixed_mask must be a 2D array\")\n        if fixed_mask.shape[1] != fixed.shape[1]:\n            raise ValueError(\n                \"fixed_mask must have same number of dimensions as fixed\"\n            )\n\n    if moving_mask is not None:\n        moving_mask = np.asarray(moving_mask)\n        if len(moving_mask.shape) != 2:\n            raise ValueError(\"moving_mask must be a 2D array\")\n        if moving_mask.shape[1] != moving.shape[1]:\n            raise ValueError(\n                \"moving_mask must have same number of dimensions as moving\"\n            )\n\n    # Calculate Centers of Mass\n    if fixed_mask is not None:\n        COM_fixed = np.mean(fixed_mask, axis=0)\n    else:\n        COM_fixed = np.mean(fixed, axis=0)\n\n    if moving_mask is not None:\n        COM_moving = np.mean(moving_mask, axis=0)\n    else:\n        COM_moving = np.mean(moving, axis=0)\n\n    # calculate translation and create transformation matrix\n    offset = COM_fixed - COM_moving\n\n    transform = np.array(\n        [\n            [1, 0, 0, offset[0]],\n            [0, 1, 0, offset[1]],\n            [0, 0, 1, offset[2]],\n            [0, 0, 0, 1],\n        ]\n    )\n\n    # apply transform\n    moving_augment = np.hstack((moving, np.ones((moving.shape[0], 1))))\n\n    moving_transformed = moving_augment @ transform.T\n\n    return moving_transformed[:, 0:3]\n</code></pre>"},{"location":"api/#MRI2FE.point_cloud_spacing","title":"<code>MRI2FE.point_cloud_spacing(dims, points=None, lims=None)</code>","text":"<p>Return the voxel spacing necessary to cover a point cloud with given voxel dimensions Can be called by either providing a point cloud or directly providing field limits.</p> <p>Parameters:</p> Name Type Description Default <code>dims</code> <code>tuple</code> <p>tuple of voxel count along each of m dimensions</p> required <code>points</code> <code>Union[list, tuple, ndarray]</code> <p>locations of n points in m dimensions with shape (n,m)</p> <code>None</code> <code>lims</code> <code>ndarray</code> <p>Min/max of point cloud space in m dimensions with shape (m,2)</p> <code>None</code> <p>Raises:</p> Type Description <code>TypeError</code> <p>If inputs are not of correct type</p> <code>ValueError</code> <p>If dims is None or if neither points nor lims is provided</p> <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple</code> <p>spacing in each dimension</p> Source code in <code>src/MRI2FE/utilities.py</code> <pre><code>def point_cloud_spacing(\n    dims: ArrayLike,\n    points: Optional[ArrayLike] = None,\n    lims: Optional[ArrayLike] = None,\n) -&gt; tuple:\n    \"\"\"Return the voxel spacing necessary to cover a point cloud with given voxel dimensions\n    Can be called by either providing a point cloud or directly providing field limits.\n\n    Args:\n        dims (tuple): tuple of voxel count along each of m dimensions\n        points (Union[list, tuple, np.ndarray], optional): locations of n points in m dimensions with shape (n,m)\n        lims (np.ndarray, optional): Min/max of point cloud space in m dimensions with shape (m,2)\n\n    Raises:\n        TypeError: If inputs are not of correct type\n        ValueError: If dims is None or if neither points nor lims is provided\n\n    Returns:\n        tuple: spacing in each dimension\n    \"\"\"\n    # Validate dims is not None\n    if dims is None:\n        raise ValueError(\"dims cannot be None\")\n\n    # check that either points or lims is provided\n    if points is None and lims is None:\n        raise ValueError(\"Must provide either points or lims for calculation\")\n\n    # convert inputs to np.ndarray\n    dims = np.asarray(dims)\n\n    if points is not None:\n        points = np.asarray(points)\n\n    if lims is not None:\n        lims = np.asarray(lims)\n\n    # check that dimensions match\n    if points is not None and not (dims.shape[0] == points.shape[-1]):\n        raise ValueError(\n            \"dims must have the same dimension as the point cloud\"\n        )\n\n    if lims is not None and not (dims.shape[0] == lims.shape[0]):\n        raise ValueError(\"dims must have the same dimension as lims\")\n\n    # find limits of point cloud if not provided\n    if lims is None and points is not None:\n        mins = np.min(points, axis=0)\n        maxes = np.max(points, axis=0)\n    elif lims is not None:\n        mins = lims[:, 0]\n        maxes = lims[:, 1]\n    else:\n        raise ValueError(\"Must provide lims or points\")\n\n    delta = maxes - mins\n\n    spacing = delta / dims\n\n    return spacing\n</code></pre>"},{"location":"api/#MRI2FE.ants_affine","title":"<code>MRI2FE.ants_affine(img)</code>","text":"<p>Extract affine transformation matrix from ANTsImage.</p> <p>Parameters:</p> Name Type Description Default <code>img</code> <code>ANTsImage</code> <p>Input ANTs image</p> required <p>Raises:</p> Type Description <code>TypeError</code> <p>If img is not an ANTsImage</p> <code>ValueError</code> <p>If img is None</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: 4x4 affine transformation matrix</p> Source code in <code>src/MRI2FE/utilities.py</code> <pre><code>def ants_affine(img: ants.core.ants_image.ANTsImage) -&gt; np.ndarray:\n    \"\"\"Extract affine transformation matrix from ANTsImage.\n\n    Args:\n        img (ants.core.ants_image.ANTsImage): Input ANTs image\n\n    Raises:\n        TypeError: If img is not an ANTsImage\n        ValueError: If img is None\n\n    Returns:\n        np.ndarray: 4x4 affine transformation matrix\n    \"\"\"\n    # Validate input is not None\n    if img is None:\n        raise ValueError(\"img cannot be None\")\n\n    # Validate input type\n    if not isinstance(img, ants.core.ants_image.ANTsImage):\n        raise TypeError(\"img must be an ANTsImage object\")\n\n    # Extract image properties\n    spacing = np.array(img.spacing)  # (sx, sy, sz)\n    direction = np.array(img.direction).reshape((3, 3))  # 3x3 rotation matrix\n    origin = np.array(img.origin)  # (ox, oy, oz)\n\n    # Compute affine matrix\n    affine_matrix = np.eye(4)  # Initialize as identity\n    affine_matrix[:3, :3] = direction * spacing  # Scale direction by spacing\n    affine_matrix[:3, 3] = origin  # Set translation\n\n    return affine_matrix\n</code></pre>"},{"location":"api/#MRI2FE.spatial_map","title":"<code>MRI2FE.spatial_map(infile)</code>","text":"<p>Convert data from NIFTI file to (4,n) array of x,y,z,voxel value in physical space</p> <p>Parameters:</p> Name Type Description Default <code>infile</code> <code>nifti1</code> <p>NIFTI file to convert</p> required <p>Raises:</p> Type Description <code>TypeError</code> <p>If infile is not an ANTsImage</p> <code>ValueError</code> <p>If infile is None</p> <p>Returns:</p> Name Type Description <code>coordinates_and_values</code> <code>ndarray</code> <p>array of x,y,z coordinates in physical space with the corresponding voxel value</p> Source code in <code>src/MRI2FE/utilities.py</code> <pre><code>def spatial_map(infile: ants.core.ants_image.ANTsImage) -&gt; np.ndarray:\n    \"\"\"Convert data from NIFTI file to (4,n) array of x,y,z,voxel value in physical space\n\n    Args:\n        infile (nb.nifti1): NIFTI file to convert\n\n    Raises:\n        TypeError: If infile is not an ANTsImage\n        ValueError: If infile is None\n\n    Returns:\n        coordinates_and_values (np.ndarray): array of x,y,z coordinates in physical space with the corresponding voxel value\n    \"\"\"\n    # Validate input is not None\n    if infile is None:\n        raise ValueError(\"infile cannot be None\")\n\n    # Validate input type\n    if not isinstance(infile, ants.core.ants_image.ANTsImage):\n        raise TypeError(\"infile must be an ANTsImage object\")\n\n    # extract data from NIFTI\n    image_data = infile.numpy()\n    affine = ants_affine(infile)\n    dimensions = image_data.shape\n\n    # create coordinates in voxel space\n    x = np.arange(dimensions[0])\n    y = np.arange(dimensions[1])\n    z = np.arange(dimensions[2])\n    xv, yv, zv = np.meshgrid(x, y, z, indexing=\"ij\")\n\n    voxel_coords = np.vstack([xv.ravel(), yv.ravel(), zv.ravel()]).T\n    voxel_coords_homogeneous = np.hstack(\n        [voxel_coords, np.ones((voxel_coords.shape[0], 1))]\n    )\n\n    # map voxel coordinates to physical space\n    physical_coords = voxel_coords_homogeneous @ affine.T\n    voxel_values = np.round(image_data.ravel())\n    coordinates_and_values = np.hstack(\n        [physical_coords[:, :3], voxel_values[:, np.newaxis]]\n    )\n\n    return coordinates_and_values\n</code></pre>"},{"location":"api/#MRI2FE.element_centroids","title":"<code>MRI2FE.element_centroids(elnodes, node_coords)</code>","text":"<p>Calculate the centroid of an element</p> <p>Parameters:</p> Name Type Description Default <code>elnodes</code> <code>array</code> <p>1D array containing EID, PID, and connected nodes</p> required <code>node_coords</code> <code>array</code> <p>2D array containing NID, xyz coordinates</p> required <p>Raises:</p> Type Description <code>TypeError</code> <p>If inputs are not numpy arrays</p> <code>ValueError</code> <p>If array dimensions or contents are invalid</p> <p>Returns:</p> Name Type Description <code>centroid</code> <code>array</code> <p>(3,) array containing average coordinate of the element</p> Source code in <code>src/MRI2FE/utilities.py</code> <pre><code>def element_centroids(\n    elnodes: Union[np.ndarray, tuple, list], node_coords: np.ndarray\n) -&gt; np.ndarray:\n    \"\"\"Calculate the centroid of an element\n\n    Args:\n        elnodes (np.array): 1D array containing EID, PID, and connected nodes\n        node_coords (np.array): 2D array containing NID, xyz coordinates\n\n    Raises:\n        TypeError: If inputs are not numpy arrays\n        ValueError: If array dimensions or contents are invalid\n\n    Returns:\n        centroid (np.array): (3,) array containing average coordinate of the element\n    \"\"\"\n    \"\"\"\n    # Validate input types\n    if not isinstance(elnodes, (np.ndarray, tuple, list)):\n        raise TypeError(\"elnodes must be a numpy array, tuple, or list\")\n    if not isinstance(node_coords, np.ndarray):\n        raise TypeError(\"node_coords must be a numpy array\")\n\n    # Validate array dimensions\n    if len(elnodes.shape) != 1:\n        raise ValueError(\"elnodes must be a 1D array\")\n    if len(node_coords.shape) != 2:\n        raise ValueError(\"node_coords must be a 2D array\")\n\n    if node_coords.shape[1] != 4:  # Must have NID and xyz coordinates\n        raise ValueError(\"node_coords must have 4 columns (NID, x, y, z)\")\n    \"\"\"\n\n    elnodes = np.asarray(elnodes)\n\n    node_ids = np.unique(elnodes[2:])\n    mask = np.zeros(len(node_coords), dtype=bool)\n    for node_id in node_ids:\n        mask |= node_coords[:, 0] == node_id\n\n    cx = np.mean(node_coords[mask, 1:], axis=0)\n\n    return cx.tolist()\n</code></pre>"},{"location":"contributing/","title":"Contributing to MRI2FE","text":""},{"location":"contributing/#getting-started","title":"Getting Started","text":""},{"location":"contributing/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure you have the following installed:</p> <ul> <li>Python 3.8 or higher</li> <li>Git</li> <li>pip</li> </ul>"},{"location":"contributing/#setting-up-the-development-environment","title":"Setting Up the Development Environment","text":"<ol> <li> <p>Fork the repository on GitHub by clicking the \"Fork\" button.</p> </li> <li> <p>Clone your fork locally:    <code>bash    git clone https://github.com/turnerjennings/MRI2FE.git    cd MRI2FE</code></p> </li> <li> <p>Create a virtual environment:    <code>bash    python -m venv venv    source venv/bin/activate  # On Windows: venv\\Scripts\\activate</code></p> </li> <li> <p>Install the package in development mode:    <code>bash    pip install -e \".[dev]\"</code></p> </li> <li> <p>Install nox to automate build and test functions:     <code>bash     pip install nox</code></p> </li> </ol>"},{"location":"contributing/#development-workflow","title":"Development Workflow","text":""},{"location":"contributing/#making-changes","title":"Making Changes","text":"<ol> <li>Make your changes in the appropriate files</li> <li>Write or update tests for your changes</li> <li>Update documentation if necessary</li> <li>Ensure your code follows our style guidelines</li> </ol>"},{"location":"contributing/#running-tests","title":"Running Tests","text":"<p>Before submitting your changes, run the nox suite to test, lint, and format the code:</p> <pre><code>#run all test and lint\nnox\n\n#run only tests\nnox -s test\nnox -s cpptest\n\n#run lint nd format\nnox -s lint\nnox -s format+\n\n</code></pre>"},{"location":"contributing/#types-of-contributions","title":"Types of Contributions","text":""},{"location":"contributing/#bug-reports","title":"Bug Reports","text":"<p>When reporting bugs, please include:</p> <ul> <li>A clear, descriptive title</li> <li>Steps to reproduce the issue</li> <li>Expected vs actual behavior</li> <li>Your environment details (Python version, OS, package version)</li> <li>Minimal code example that demonstrates the issue</li> </ul>"},{"location":"contributing/#feature-requests","title":"Feature Requests","text":"<p>For new features:</p> <ul> <li>Explain the motivation and use case</li> <li>Provide a detailed description of the proposed functionality</li> <li>Consider backward compatibility</li> <li>Include examples of how the feature would be used</li> </ul>"},{"location":"contributing/#code-contributions","title":"Code Contributions","text":""},{"location":"contributing/#pull-request-process","title":"Pull Request Process","text":"<ol> <li>Update documentation for any new features or API changes</li> <li>Add tests that cover your changes</li> <li>Ensure all tests pass and code quality checks succeed</li> <li>Create a pull request with a clear title and description</li> </ol>"},{"location":"contributing/#documentation","title":"Documentation","text":"<p>Documentation improvements are always welcome! This includes:</p> <ul> <li>Fixing typos or clarifying existing documentation</li> <li>Adding examples or tutorials</li> <li>Improving API documentation</li> <li>Translating documentation</li> </ul>"},{"location":"contributing/#project-structure","title":"Project Structure","text":"<pre><code>your-package-name/\n\u251c\u2500\u2500 docs/                       # Documentation source\n\u251c\u2500\u2500 include/                    # cpp header files\n\u251c\u2500\u2500 src/\n    \u251c\u2500\u2500 cpp/                    # cpp code files\n    \u251c\u2500\u2500 MRI2FE/                 # python package files    \n\u251c\u2500\u2500 test/                       # Test files\n\u251c\u2500\u2500 noxfile.py                  # nox session configuration\n\u251c\u2500\u2500 pyproject.toml              # Project configuration\n\u251c\u2500\u2500 install_windows.bat         # Windows installation script\n\u251c\u2500\u2500 install_linux.sh            # Linux installation script\n\u251c\u2500\u2500 install_mac.sh              # MacOS installation script\n\u251c\u2500\u2500 pyproject.toml              # Project configuration\n\u251c\u2500\u2500 README.md                   # Project overview\n\u2514\u2500\u2500 CONTRIBUTING.md             # This file\n</code></pre>"},{"location":"quickstart/","title":"Quick Start","text":"<p>Models can be generated quickly from medical imaging data using the built in helper functions.  At it's core, this library contains functions which perform 4 operations:</p> <ol> <li>Generating a tetrahedral mesh from a segmented, labeled MRI image.</li> <li>Segmented MRE data into similar regions and calculating prony series viscoelastic parameters for each region.</li> <li>Transforming the MRE data into the segmented MRI space and mapping the segmented MRE material assignments onto the FE mesh.</li> <li>Organizing and writing the data from steps 1-3 to a compatible file format.</li> </ol>"},{"location":"quickstart/#examples","title":"Examples","text":"<p>All steps can be completed at once with a short build script:</p> <pre><code>import MRI2FE\n\n#define structural MRI paths\nlabeled_geom_path = \"path/to/labeled_image.nii\"\ngeom_roi_mask_path = \"path/to/roi_mask.nii\"\n\n#define MRE geometry paths\nMRE_geometry_paths = [\"path/to/30Hzgeom.nii\",\n                      \"path/to/50Hzgeom.nii\",\n                      \"path/to/70Hzgeom.nii\"]\n\nMRE_mask_path = \"/path/to/MRE_mask.nii\"\n\n#define a list of tuples containing the MRE data\n#either stiffness/damping ratio or G'/G\"\nMRE_properties_paths = [\n    (\"path/to/30Hzstiffness.nii\",\"path/to/30Hzdamping.nii\"),\n    (\"path/to/50Hzstiffness.nii\",\"path/to/50Hzdamping.nii\"),\n    (\"path/to/70Hzstiffness.nii\",\"path/to/70Hzdamping.nii\")\n]\n\n#model builder workflow: returns model object and writes to output\n\nmdl = (\n    MRI2FE.FEModelbuilder()\n    .mesh(img_path = labeled_geom_path,\n          img_labels = [\"region1\",\"region2\",\"region3\"])\n    .map_mre(target_label = 1,\n             MRE_type = \"stiffness_damping\",\n             MRE_geom = MRE_geometry_paths,\n             MRE_mask = MRE_mask_path,\n             MRE_frequency = [30,50,70],\n             MRE_to_transform = MRE_properties_paths)\n    .write(\"/output/path/example.k\")\n    .build()\n)\n\n</code></pre> <p>The FEModelbuilder pipeline provides a convenient way to combine all steps of the model generation process.  If additional control over each step is necessary, each step of the build process can be run separately with additional options:</p> <pre><code>import MRI2FE\nimport meshio\n\n#create a blank model\nmdl = MRI2FE.FEModel(title = \"example\",\n                     source = \"example\")\n\n#create a mesh with mesh quality constraints\nlabeled_geom_path = \"path/to/geometry.nii\"\n\nmesh = MRI2FE.mesh_from_nifti(labeled_geom_path,\n                              optimize=True,\n                              facetAngle=40,\n                              cellRadiusEdgeRatio=2.0)\n\nmdl.from_meshio(mesh)\n\n#load a mesh generated using an external program\nexternal_mesh = meshio.read(\"path/to/mesh.stl\")\n\nmdl.from_meshio(external_mesh)\n\n#transform MRE data using an affine transform\n\nMRE_geometry_paths = [\"path/to/30Hzgeom.nii\",\n                      \"path/to/50Hzgeom.nii\",\n                      \"path/to/70Hzgeom.nii\"]\n\nMRE_mask_path = \"/path/to/MRE_mask.nii\"\n\nMRE_properties_paths = [\n    (\"path/to/30Hzstiffness.nii\",\"path/to/30Hzdamping.nii\"),\n    (\"path/to/50Hzstiffness.nii\",\"path/to/50Hzdamping.nii\"),\n    (\"path/to/70Hzstiffness.nii\",\"path/to/70Hzdamping.nii\")\n]\n\n_, transformed = MRI2FE.MRE.coregister_MRE_images(\n    labeled_geom_path,\n    target_label = 4,\n    MRE_geom = MRE_geometry_paths,\n    type_of_transform = \"Affine\",\n    MRE_to_transform = MRE_properties_paths,\n    MRE_frequency = [30,50,70])\n\n#map MRE onto mesh with custom prony series values\nmdl = MRI2FE.MRE.map_MRE_to_mesh(\n    mdl,\n    region_properties = prony_series_values,\n    label_background_id = 0,\n    region_prefix = \"brain\"\n)\n\n#write output\nmdl.write_lsdyna(\"/save/path/example.k\")\n\n</code></pre>"}]}